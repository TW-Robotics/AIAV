{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04d2f9d9-bb9a-42d8-b184-7472c1ae14b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 dataset images (without augmentation)\n",
      "Read the following classes:\n",
      "['WinkelGross', 'Sicherung', 'Zahnrad', 'LWinkel']\n"
     ]
    }
   ],
   "source": [
    "# Dieses Skript lädt das vortrainierte Modell und überprüft die Inferenz-Geschwindigkeit mittels der Intel Extension for Pytorch.\n",
    "# Basiert auf dem Detectron2 Tutorial: https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5\n",
    "#\n",
    "# This code is available under a GPL v3.0 license and comes without\n",
    "# any explicit or implicit warranty.\n",
    "#\n",
    "# (C) Simon Schwaiger 2024 <schwaige@technikum-wien.at>\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "## Import von Detectron2\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "## Laden des Datensatzes\n",
    "datasetPath = \"/app/detectronDataset\"\n",
    "classesFile = os.path.join(datasetPath, \"classNames.txt\")\n",
    "modelWeightFile = os.path.join(datasetPath, \"model_final.pth\")\n",
    "\n",
    "def getFiles(directory, ext=(\".jpg\", \".png\")):\n",
    "    \"\"\"Gibt alle Dateien in einem Verzeichnis von bestimmten Dateitypen zurück \"\"\"\n",
    "    files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "    if ext == []: retArr = files\n",
    "    else: retArr = [ file for file in files if file.endswith(ext) ]\n",
    "    return retArr\n",
    "\n",
    "trainImages = getFiles(datasetPath)\n",
    "\n",
    "# Lesen der Klassennamen\n",
    "with open(classesFile, \"r\") as f:\n",
    "    classesList = f.read().splitlines()\n",
    "\n",
    "print(\"Found {} dataset images (without augmentation)\".format(len(trainImages)))\n",
    "print(\"Read the following classes:\")\n",
    "print(classesList)\n",
    "\n",
    "def formatCOCODict(idx, imgname, datasetPath=datasetPath):\n",
    "    \"\"\"Formatiert ein Bildt im COCO Format (Bild + Annotierung) zurück \"\"\"\n",
    "    # Pfad von Bild und Bildbeschreibung\n",
    "    imgpath = os.path.join(datasetPath, imgname)\n",
    "    annotationPath = os.path.splitext(imgpath)[0] + \".txt\"\n",
    "    # Ermittlung der Bildbreite und Höhe\n",
    "    img = cv2.imread(imgpath)\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    # Lesen der Bildannotierung\n",
    "    with open(annotationPath, \"r\") as f:\n",
    "        annotationLines = f.readlines()\n",
    "    # Konvertierung der Annotierung und Speichern der Metadaten\n",
    "    annotations = []\n",
    "    for line in annotationLines:\n",
    "        classIdx, x, y, w, h = line.split(\" \")\n",
    "        annotations.append(\n",
    "            {\n",
    "                \"bbox\": [float(x)*width-(float(w)*width/2), float(y)*height-(float(h)*height/2), float(w)*width, float(h)*height],\n",
    "                \"bbox_mode\": 1,\n",
    "                \"category_id\": int(classIdx)\n",
    "            }\n",
    "        )\n",
    "    #\n",
    "    return {\n",
    "        \"file_name\": imgpath,\n",
    "        \"image_id\": idx,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"annotations\": annotations\n",
    "    }\n",
    "\n",
    "# Lediglich das erste Bild im Datensatz wird als Testbild verwendet, da wir nur weniger Bilder zum Trainieren zur Verfügung haben\n",
    "def getMarkerDicts(trainImages=trainImages[1:]):\n",
    "    return [\n",
    "        formatCOCODict(idx, imgname)\n",
    "        for idx, imgname in enumerate(trainImages)\n",
    "    ]\n",
    "\n",
    "def getMarkerDictsTest(trainImages=trainImages[:1]):\n",
    "    return [\n",
    "        formatCOCODict(idx, imgname)\n",
    "        for idx, imgname in enumerate(trainImages)\n",
    "    ]\n",
    "\n",
    "# Registrierung der Datensätze\n",
    "DatasetCatalog.register(\"marker_train\", getMarkerDicts)\n",
    "MetadataCatalog.get(\"marker_train\").set(thing_classes=classesList)\n",
    "marker_metadata = MetadataCatalog.get(\"marker_train\")\n",
    "\n",
    "## Erstellung einer Modellkonfiguration, die dem trainierten Modell gleicht\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"marker_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 500\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classesList)\n",
    "\n",
    "# Laden des vortrainierten Modells\n",
    "cfg.MODEL.WEIGHTS = modelWeightFile\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "\n",
    "cfg.MODEL.DEVICE = 'cpu'\n",
    "\n",
    "# Instanziierung des Predictors basierend auf der Konfiguration\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "## Laden der Bildvisualisierung\n",
    "from detectron2.utils.visualizer import ColorMode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cddc256a-2efa-4026-ac20-a0d40c81bbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/intel/oneapi/intelpython/latest/lib/python3.9/site-packages/intel_extension_for_pytorch/frontend.py:462: UserWarning: Conv BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\n",
      "/opt/intel/oneapi/intelpython/latest/lib/python3.9/site-packages/intel_extension_for_pytorch/frontend.py:469: UserWarning: Linear BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Optimierung des Modells mittels intel extension for pytorch, um Inferenz auf eingebetteter Intel CPU zu beschleunigen\n",
    "import intel_extension_for_pytorch as ipex\n",
    "\n",
    "model = ipex.optimize(predictor.model)\n",
    "predictor.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d65035c-017c-4e56-ac3f-304cdbb8d7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9bcf6779164e0caa2a8301cfbdf64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=23)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/intel/oneapi/intelpython/latest/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 46s, sys: 7.88 s, total: 1min 53s\n",
      "Wall time: 28.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Messung der Zeit zur Voraussage aller Bilder im Datensatz\n",
    "\n",
    "# Anzeige des Fortschritts\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "f = IntProgress(min=0, max=len(trainImages))\n",
    "display(f)\n",
    "\n",
    "for imgname in trainImages:\n",
    "    imgpath = os.path.join(datasetPath, imgname)\n",
    "    img = cv2.imread(imgpath)\n",
    "    outputs = predictor(img)\n",
    "    f.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d56c47-066f-45fd-a0c2-31e1de1b43c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
