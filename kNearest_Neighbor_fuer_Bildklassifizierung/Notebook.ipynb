{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementierung einer k Nearest Neighbor (kNN) Klassifizierung von handgeschriebenen Buchstaben\n",
    "Das Notebook beschreibt die Implementierung eines k Nearest Neighbor Models für das klassifizieren von Bildern. Genauer gesagt, wollen wir handgeschriebene Buchstaben des EMNIST Datensatzes klassifizieren. \n",
    "\n",
    "## Aufbau:\n",
    "Der Aufbau des Notebooks ist in drei grobe Teile geteilt. Zuerst wird der Datensatz eingelesen und vorbereitet. Anschlißend wird das Modell definiert und trainiert. Abschließend wird das kNN Model verwendet um neue Buchstaben zu klassifizieren. \n",
    "### Abschnitt 1: Datensatz vorbereiten\n",
    "Im ersten Teil des Notebooks wird der Datensatz vorbereitet. Hierzu wird ein [Dictonary](https://kapernikov.com/tutorial-image-classification-with-scikit-learn/) angelegt. Anschließend kann mit dem Dictonary eine reshape Funktion aufgerufen werden um die Bildmatrizen in einen Vektor umzuwandeln wie auch schon in der Theorie besprochen wurde. \n",
    "### Abschnitt 2: Erstellen des Modells\n",
    "In diesem Abschnitt wird das Modell mittels der [sklearn-Bibliothek](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) definiert. Dies ist auch der Abschnitt bei dem Parameter getuned werden können. Abschließend wird das Modell trainiert und getestet. \n",
    "### Abschnitt 3: Webcam Implementierung\n",
    "Im letzten Abschnitt wird das trainierte Modell eingesetzt. Das kNN Model predicts (klassifiziert) für jedes Bild im Demo-Ordner um welchen Buchstaben es sich handelt. \n",
    "\n",
    "## Ordnerstruktur: \n",
    "Anbei ist noch die Ordnerstruktur aufgelistet. Der Demo Ordner beinhaltet handgeschriebene Buchstabenbilder welche nicht für das Trainieren des Models verwendet werden. Diese werden nach dem Trainieren verwendet, damit wir das Model in action sehen können. Der data Ordner gibt die Klassen vor. Hier werden 26 Ordner angelegt welche jeweils mit einem kleinbuchstaben beschriftet werden. Anschließend werden dort die entsprechenden Bilder abgelegt. So kann der Ordnername als Klasse herangezogen werden und somit haben die Bilder darin gleich ein Label. Wenn eigene Daten verwendet werden wollen, können einfach Bilder und Ordnernamen geändert werden. \n",
    "\n",
    "Die Datei E-MNIST_{width}x{height}px.pkl ist eine Datei die im Laufe des Notebooks generiert wird und den Datensatz als [Dictonary](https://kapernikov.com/tutorial-image-classification-with-scikit-learn/) abspeichert. Die Datei *.ipynb ist das Storyboard selbst. Die dritte Datei in für den Use-Case ist die requirements Datei. Diese kann eingesetzt werden um die benötigten Bibliotheken und Systemvorraussetzungen zu installieren. Eine (externe) Tutorial dazu findet man [hier](https://note.nkmk.me/en/python-pip-install-requirements/). \n",
    "\n",
    "1. `demo`\n",
    "    - _demo images_\n",
    "    \n",
    "2. `data`\n",
    "    - Ordner 'a'-'z'\n",
    "3. `eigenfaces`\n",
    "    - _eigenfaces Bilder_ \n",
    "\n",
    "4. `miniUsecases13_KNN.ipynb`\n",
    "5. `E-MNIST_{width}x{height}px.pkl`\n",
    "6. `requirements.txt`\n",
    "7. `demo.gif`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Resultat: \n",
    "![alt text](./demo.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abschnitt 0: Importieren der generellen notwendigen Bibliotheken\n",
    "Wir empfehlen die notwendigen Bibliotheken über die requirements.txt Datei zu installieren. Das ermöglicht es, dass automatisch die richtigen Versionen installiert werden. Sollte eine Library nicht vorhanden sein, dann kann die häufig auch mit `pip3 <package-name\\>` nachinstalliert werden.\n",
    "\n",
    "Sind alle libraries vorhanden, entsteht kein Output bei der nächsten Zelle. Im laufe des Notebooks werden weitere Bibliotheken benötigt. Diese werden erst in späteren Zellen aufgerufen um jeweils bei den entsprechenden Codesnipped zu garantieren, dass sie im Workspace geladen sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data von miniUsecase11 logistic regression \n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2grey\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import warnings\n",
    "from scipy.sparse import (spdiags, SparseEfficiencyWarning, csc_matrix,\n",
    "    csr_matrix, isspmatrix, dok_matrix, lil_matrix, bsr_matrix)\n",
    "warnings.simplefilter('ignore',SparseEfficiencyWarning) \n",
    "warnings.simplefilter('ignore',UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verschiedene Einstellungen um das Programm anzupassen\n",
    "\n",
    "data_path: gibt den relativen Pfad zu dem Datensatz (Ordner mit Bildern) an.\n",
    "\n",
    "os.listdir(data_path): Zeigt die Ordner an, welche die Bilder für das Trainieren enthalten sollen.\n",
    "\n",
    "SIZE: definiert die größe des Bildes. Hier kann eingestellt werden wie sehr das Bild \"verkleinert\" werden soll. Ein guter Startpunkt ist meist _<original_imagesize/rescaling>_ wobei rescaling einfach als Skalar gewählt werden kann. In dem Beispiel verwenden wir ein viertel der Pixellänge. Sprich ein 416x416 Pixelbild ist dann nur mehr 104x104px groß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Pfad und Bildgröße ändern\n",
    "\n",
    "data_path = os.getcwd() + \"/data\"\n",
    "os.listdir(data_path) \n",
    "SIZE = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusatzfunktion für das preperieren der Daten \n",
    "Diese funktion lädt alle Bilder in den Workspace (aus dem definierten Pfad) und macht foglende 2 Aktionen:\n",
    "- Resize: Skaliert die Bilder entsprechend der Vorgabe\n",
    "- Dictionary: Erstellt ein Dictionary mit Labels und Metadata (Datensatz für das Trainieren). Der output wird als _pickle file_ im Workspace abgespeichert.\n",
    "\n",
    "Parameter: \n",
    "- src: gibt den Pfad zu den Daten an\n",
    "- pklname: erstellt den Namen für die Pickle Datei\n",
    "- include: Includiert als String Liste der Klassen ('a'-'z')\n",
    "- width: gibt die größe der Bilder/Resize an\n",
    "\n",
    "Mehr Infos zur [Datenverarbeitung](https://kapernikov.com/tutorial-image-classification-with-scikit-learn/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "import joblib\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "# Funktionsdefinition \n",
    "def resize_all(src, pklname, include, width = 150, height=None):\n",
    "    height = height if height is not None else width #ERRORHANDLING\n",
    "    \n",
    "# definiert den Datansatz als Dictionary \n",
    "    data = dict()\n",
    "    data['description'] = 'resized ({0}x{1}) images in rgb'.format(int(width), int(height))\n",
    "    data['label'] = []\n",
    "    data['filename'] = []\n",
    "    data['data'] = []   \n",
    "\n",
    "    pklname = f\"{pklname}_{width}x{height}px.pkl\"\n",
    "\n",
    "    for subdir in os.listdir(src):\n",
    "        if subdir in include:\n",
    "            print(subdir)\n",
    "            current_path = os.path.join(src, subdir)\n",
    " \n",
    " # itteriert über alle Bilder im Datensatz \n",
    "            for file in os.listdir(current_path):\n",
    "                if file[-3:] in {'jpg', 'png'}:\n",
    "                    im = imread(os.path.join(current_path, file))\n",
    "                    im = resize(im, (width, height)) #[:,:,::-1]\n",
    "                    data['label'].append(subdir)\n",
    "                    data['filename'].append(file)\n",
    "                    data['data'].append(im)\n",
    " \n",
    "# erstellt die Pickle file\n",
    "        joblib.dump(data, pklname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatieren des Datensatzes\n",
    "Hier wird die Hilfsfunktion aufgerufen, die für das erstellen des Datensatzes notwendig ist. Ebenso werden hier die Parameter übergeben. Zu beachten ist, dass hier nur _.jpg_ und _.png_ Bilder verarbeitet werden können. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w\n",
      "n\n",
      "c\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2957/3089432630.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#FUNCTION CALL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mresize_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpklname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Funktionsaufruf für das erstellen der pkl-Datei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2957/1045800015.py\u001b[0m in \u001b[0;36mresize_all\u001b[0;34m(src, pklname, include, width, height)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#[:,:,::-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                                (plugin, kind))\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/skimage/io/_plugins/imageio_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# Get reader and read first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[0;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_read_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mmodename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODENAMES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/imageio/core/format.py\u001b[0m in \u001b[0;36msearch_read_format\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;31m# Select the first that can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_formats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/imageio/core/format.py\u001b[0m in \u001b[0;36mcan_read\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mGet\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mformat\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mread\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \"\"\"\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcan_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/imageio/plugins/pillow.py\u001b[0m in \u001b[0;36m_can_read\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mfactory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPEN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugin_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0maccept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirstbytes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirstbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/imageio/core/request.py\u001b[0m in \u001b[0;36mfirstbytes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \"\"\"\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_firstbytes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_first_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_firstbytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m_read_first_bytes\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;31m# Read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_firstbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_n_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m             \u001b[0;31m# Set back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/imageio/core/request.py\u001b[0m in \u001b[0;36mread_n_bytes\u001b[0;34m(f, N)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \"\"\"\n\u001b[1;32m    482\u001b[0m     \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0mextra_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextra_bytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_name = 'E-MNIST'   # Name für die Beschreibung des Datensatzes\n",
    "width = SIZE                        # Definierte Bildgröße übergeben (Zelle 2)\n",
    "include = {'a','b','c','d','e','f',\n",
    "           'g','h','i','j','k','l',\n",
    "           'm','n','o','p','q','r',\n",
    "           's','t','u','v','w','x',\n",
    "           'y','z'}   # Ordner angeben\n",
    " \n",
    "#FUNCTION CALL\n",
    "resize_all(src=data_path, pklname=base_name, width=width, include=include) # Funktionsaufruf für das erstellen der pkl-Datei "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informationen vom Datensatz\n",
    "anbei werden bei korrektem erstellen des Dictionarys die Informationen dazu angezeigt. Diese werden über die Pickle Datei ausgelesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der gefundenen Daten:  124784\n",
      "keys:  ['description', 'label', 'filename', 'data']\n",
      "Beschreibung:  resized (28x28) images in rgb\n",
      "Bild Form  (28, 28)\n",
      "Labels: ['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r'\n",
      " 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'w': 4800,\n",
       "         'n': 4800,\n",
       "         'c': 4796,\n",
       "         'm': 4800,\n",
       "         'u': 4800,\n",
       "         't': 4800,\n",
       "         'd': 4795,\n",
       "         'e': 4800,\n",
       "         'k': 4800,\n",
       "         'y': 4800,\n",
       "         'b': 4796,\n",
       "         'h': 4800,\n",
       "         'o': 4800,\n",
       "         'p': 4800,\n",
       "         'i': 4800,\n",
       "         'l': 4800,\n",
       "         'a': 4797,\n",
       "         'q': 4800,\n",
       "         'f': 4800,\n",
       "         'x': 4800,\n",
       "         'g': 4800,\n",
       "         'r': 4800,\n",
       "         'z': 4800,\n",
       "         'v': 4800,\n",
       "         'j': 4800,\n",
       "         's': 4800})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    " \n",
    "data = joblib.load(f'{base_name}_{width}x{width}px.pkl')    # Laden der Datei\n",
    "print('Anzahl der gefundenen Daten: ', len(data['data']))   \n",
    "print('keys: ', list(data.keys()))                          # Zeigt die einzelnen Komponenten  \n",
    "print('Beschreibung: ', data['description'])                \n",
    "print('Bild Form ', data['data'][0].shape)                  # Format anzeigen. Nützlich für das Reshapen nachher\n",
    "print('Labels:', np.unique(data['label']))                  # Labels für die Klassifizierung\n",
    "Counter(data['label'])                                      # Aufteilung anzeigen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensatz Beispiel der beiden Klassen\n",
    "Folgende Zelle lädt jeweils ein Bild/Klasse. Sollten hier nicht erwartete Bilder erscheinen muss der Datensatz überprüft werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x288 with 26 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = np.unique(data['label'])           # Labels auslesen\n",
    "\n",
    "\n",
    "# Matplot handling um Achsen zu erstellen\n",
    "fig, axes = plt.subplots(1, len(labels))    # Plot definieren\n",
    "fig.set_size_inches(15,4)                   # Größe\n",
    "fig.tight_layout() \n",
    "\n",
    "# Generiert einen Plot mit einem Bild aus jeder Klasse\n",
    "for ax, label in zip(axes, labels):\n",
    "    idx = data['label'].index(label)\n",
    "    ax.imshow(data['data'][idx])\n",
    "    ax.axis('off')\n",
    "    ax.set_title(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensatz umformen\n",
    "Die derzeitige Form eines eingelesenen Bildes ist <index, breite, höhe, schichten> mit index für die Anzahl der Elemente, Breite/Höhe gibt die Bildgröße in Pixel an und Schichten beschreibt die Art des Bildes (3 = RGB)\n",
    "\n",
    "Um eine Klassifikation durchzuführen benötigt das System einen Vektor mit maximal 2 Dimensionen. Wir wollen einen Vektor mit <index, pixel_vektor>, wobei index gleich bleibt um mit den Labels (y-Vektor) übereinzustimmen. Der pixel_vektor (\"Daten\" entsprechend zum Index im X-Vektor) wird aus den restlichen Ebenen gebildet, um einen 1*n Vektor zu erhalten.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Form: (124784, 28, 28)\n",
      "Umgeformter Datensatz der Form: (124784, 784)\n",
      "Der Index muss mit der Labels größe Übereinstimmen. \n",
      "Labels größe: (124784,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data['data'])                                      # Einlesen der Bilder\n",
    "print(\"Original Form: {}\".format(X.shape))                      \n",
    "x = X.reshape(X.shape[0], X.shape[1]* X.shape[2])   # Umformen auf die beschriebene Größe\n",
    "print(\"Umgeformter Datensatz der Form: {}\".format(x.shape))\n",
    "\n",
    "y = np.array(data['label'])                                     # Einlesen der Labels\n",
    "print(\"Der Index muss mit der Labels größe Übereinstimmen. \\nLabels größe: {}\".format(y.shape)) #Abgleichen ob die Form übereinstimmt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abschnitt 2: Erstellen des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN-Model\n",
    "(1) Datensatz in Trainings/Test Daten aufteilen <br>\n",
    "(2) principal component analysis (PCA) definieren <br>\n",
    "(3) Modell definieren <br>\n",
    "(4) Genauigkeit auswerten <br>\n",
    "\n",
    "\n",
    "Zum Einsatz kommt hier die sklearn Bibliothek welche ermöglicht ein bereits existierendes Model einzubinden und nur die Parameter zu definieren. Dadurch sind features wie Skalieren, PCA oder das Trainieren leicht umgesetzt. \n",
    "\n",
    "Weitere Dokumentation: <br>\n",
    "[Modelle mit sklearn](https://rpubs.com/Sharon_1684/454441) <br>\n",
    "[kNN Dokumentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufteilen und Transformieren (PCA)\n",
    "#### (1) Datensatz Teilen\n",
    "Im ersten Abschnitt der folgenden Zelle wird der Datensatz in Trainings und Test Daten aufgeteilt. Das ermöglicht das trainieren und das anschließende testen des Models \n",
    "\n",
    "#### (2) Principal Component Analysis (PCA)\n",
    "Im zweiten Teil wird eine PCA auf den Datensatz angewandt. Dies ermöglicht, dass nicht alle Pixel als Trainingsdaten herangezogen werden sonder nur herausstechende Features. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "v    3627\n",
       "o    3625\n",
       "j    3624\n",
       "k    3621\n",
       "q    3619\n",
       "z    3614\n",
       "f    3612\n",
       "l    3611\n",
       "d    3607\n",
       "w    3607\n",
       "p    3606\n",
       "x    3606\n",
       "r    3604\n",
       "h    3603\n",
       "u    3601\n",
       "m    3600\n",
       "g    3598\n",
       "n    3598\n",
       "t    3595\n",
       "y    3587\n",
       "s    3586\n",
       "i    3583\n",
       "b    3572\n",
       "a    3565\n",
       "c    3563\n",
       "e    3554\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aufteilen des Datensatzes (1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,\n",
    "                                                    y,\n",
    "                                                    test_size=.25,\n",
    "                                                    random_state=1234123)\n",
    "\n",
    "\n",
    "# (2) Skalieren\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(X_train)\n",
    "x_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "#  PCA (2)\n",
    "#pca = PCA(.95)                                  # verwendet 95% der Komponenten und erstellen der \"PCA-Instanz\"\n",
    "pca = PCA(15)                                  # verwendet 99% der Komponenten und erstellen der \"PCA-Instanz\"\n",
    "pca.fit(X_train)                                # PCA aufgrund von Datensatz auslegen\n",
    "pca.n_components_   \n",
    "print(pca.n_components_)                            \n",
    "X_train = pca.transform(X_train)                # PCA auf Datensatz anwenden\n",
    "X_test = pca.transform(X_test)                  # PCA auf Test Daten anwenden\n",
    "pd.Series(y_train).value_counts()               # Evaluieren der Verteilung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP 5 eigenfaces \n",
    "\n",
    "nbr_eigenfaces = 10\n",
    "\n",
    "\n",
    "eigenfaces = pca.components_[:nbr_eigenfaces]\n",
    "eigenfaces = eigenfaces.reshape((nbr_eigenfaces, int(SIZE), int(SIZE)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(nbr_eigenfaces):\n",
    "\n",
    "    min_ = np.amin(eigenfaces[i])\n",
    "    max_ = np.amax(eigenfaces[i])\n",
    "\n",
    "    tmp = ((eigenfaces[i] - min_) / (max_-min_)) * 255\n",
    "\n",
    "    filename = \"eigenfaces/eigenface\" + str(i) + \".png\"  \n",
    "    cv2.imwrite(filename, tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Modell definieren\n",
    "In der folgenden Zelle wird das Deep k-Nearest Neigbors Modell definiert. Hierzu wird der KNeighborsClassifier von der sklearn-Bibliothek eingefügt. \n",
    "\n",
    "\n",
    "#### Weitere Parameter: \n",
    "Den Parameter den wir am leichtesten einstellen können ist die Anzahl der NNeighbors. Hier kann man einstellen wie viele Nachbarn das Modell berücksichtigen soll.\n",
    "Mehr Informationen zu den [Parametern](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "kNN = KNeighborsClassifier(n_neighbors=3) # (3) kNN Definition\n",
    "# Parameters:\n",
    "# n_neigbors: Gibt die Anzahl der Nachbarn in der Anfrage an \n",
    "# algorithm:{‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, default=’auto’\n",
    "#            konkrete Algorithmus zum Berechnen, default wird versucht den besten für den Datensatz entsprechenden Algorithmus zu verwenden  \n",
    "\n",
    "\n",
    "\n",
    "kNN.fit(X_train, y_train)  # Modell Trainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Genauigkeit auswerten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy:  0.7682715732786255\n"
     ]
    }
   ],
   "source": [
    "y_pred = kNN.predict(X_test)                     # Prediction für den Test Datensatz\n",
    "accuracy = accuracy_score(y_test, y_pred)        # Auswertung\n",
    "print('Model accuracy: ', accuracy)              # Ausgabe der Genauigkeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abschnitt 3: Anwenden des Models\n",
    "In der folgenden Zelle werden die Testbilder eingelesen eine Prediction durchgeführt. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************\n",
      "Example Image: 1\n",
      "Predicted Number: (['b'])\n",
      "66.67%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#libraries\n",
    "from skimage.transform import resize\n",
    "from sklearn.decomposition import PCA\n",
    "import cv2\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "cv2.namedWindow('Prediction | press q to exit', 0)\n",
    "i = 0\n",
    "for filename in os.listdir(\"demo\"):\n",
    "    img = cv2.imread(os.path.join(\"demo/\",filename), 0)\n",
    "    height = width\n",
    "    img = resize(img, (width, height))\n",
    "    if img is None:\n",
    "        print(os.path.join(\"demo/\",filename))\n",
    "        break\n",
    "    else: \n",
    "        # Bild aus einer Matrix in einen Vektor umformen \n",
    "        image = img.reshape(1 ,-1)\n",
    "\n",
    "        # Bild an das Modell anpassen (Skalieren und PCA anwenden)\n",
    "        image = scaler.transform(image)\n",
    "        image = pca.transform(image)\n",
    "\n",
    "        #Predict \n",
    "        y_new_prob  = kNN.predict_proba(image)\n",
    "        y_new  = kNN.predict(image)\n",
    "\n",
    "        # Wahrscheinlichkeit des Bildes (bei einer Klassifizierung) in Prozent umrechnen\n",
    "        prob = y_new_prob[0]*100\n",
    "\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(\"***************\")\n",
    "        i = i+1\n",
    "        print(\"Example Image: {}\".format(i))\n",
    "        #Auswertung für die \"live\" Darstellung\n",
    "        print(\"Predicted Number: ({})\".format(y_new))\n",
    "        idx = (ord(y_new[0]) - ord(\"a\"))\n",
    "        print(\"{:.2f}%\".format(prob[idx]))\n",
    "        \n",
    "        #Ausgabe \n",
    "        cv2.imshow('Prediction | press q to exit', img)\n",
    "        #User Input für das beenden des Darstellen  \n",
    "        if cv2.waitKey(0) & 0xFF == ord('q'):    \n",
    "            break\n",
    "\n",
    "\n",
    "# Stream schließen und Window Handling\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
