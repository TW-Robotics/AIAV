# Dies ist das CNN Trainingsskript.
#
# This code is available under a GPL v3.0 license and comes without
# any explicit or implicit warranty.
#
# (C) Wilfried Woeber 2020 <wilfried.woeber@technikum-wien.at>
from keras.applications import VGG16    #Import the VGG capabilities
from keras import models                #Import models --> several layers
from keras import layers                #Layers :-)
from keras import optimizers            #Keras optimizer
from keras.preprocessing.image import ImageDataGenerator        #Data generator for augmention
from keras.layers import Input, Flatten, Dense, Dropout
from keras.models import Model
from sklearn.metrics import confusion_matrix        #Confusion matrix
import sys 
import numpy as np
#------------------------------#
#--- Define global settings ---#
#------------------------------#
train_dir="./TRAIN"         #Train folder generated by bash script
validation_dir="./TEST"     #Test folder generated by test script
image_size=224              #Image size of VGG - we interpolate!
train_batchsize = 100       #Used batches for training
val_batchsize = 100         #Validation batchsize
epochs=2                    #Number of epochs to train
Augmention=True             #We want augmention
print("Augmention:", Augmention)
#--------------------------#
#--- Load the VGG model ---#
#--------------------------#
vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))
#--- Freeze the layers except the last 4 layers ---#
for layer in vgg_conv.layers[:-4]:
    layer.trainable = False
#------------------------#
#--- Create the model ---#
#------------------------#
#--- We have to do this cuz of Keras-viz ---#
last = vgg_conv.output
x = Flatten()(last)
x= Dense(1024,activation='relu')(x)
x=Dropout(0.5)(x)
pred=Dense(10,activation='softmax')(x)
model = Model(vgg_conv.input,pred)
#---  Show a summary of the model ---#
model.summary()
#-----------------------------------#
#--- Define trainign environment ---#
#-----------------------------------#
#--- Image data generators ---#
if(Augmention):
    train_datagen = ImageDataGenerator(                     #Augmention
        rescale=1./255,
          rotation_range=20,
          width_shift_range=0.2,
          height_shift_range=0.2,
          horizontal_flip=True,
          fill_mode='nearest')
else:
    train_datagen = ImageDataGenerator(rescale=1./255)     #No augmention
validation_datagen = ImageDataGenerator(rescale=1./255)
#--- Get generators ---#
train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(image_size, image_size),
        batch_size=train_batchsize,
        class_mode='categorical')
validation_generator = validation_datagen.flow_from_directory(
        validation_dir,
        target_size=(image_size, image_size),
        batch_size=val_batchsize,
        class_mode='categorical',
        shuffle=False)
#-------------------#
#--- Train model ---#
#-------------------#
model.compile(loss='categorical_crossentropy',
             optimizer=optimizers.RMSprop(lr=1e-4),
             metrics=['acc'])
history = model.fit_generator(
      train_generator,
      steps_per_epoch=train_generator.samples/train_generator.batch_size ,
      epochs=epochs,
      validation_data=validation_generator,
      validation_steps=validation_generator.samples/validation_generator.batch_size,
      verbose=1)
#-------------------#
#--- Store model ---#
#-------------------#
print('Accuracy_fin:',history.history['val_acc'][-1])   #Print accuracy
#------------------#
#--- Test model ---#
#------------------#
train_im = ImageDataGenerator(rescale=1./255)
def test_images():
    train_generator = train_im.flow_from_directory (
            validation_dir, 
            target_size=(224, 224),
            color_mode='rgb',
            batch_size=10000,
            shuffle = False,
            class_mode='categorical'
         )
    x =  train_generator
    return x[0][0], x[0][1], train_generator.filenames
test_data = test_images()
#--- Do predcition ---#
prediction = model.predict(test_data[0])
prediction_row = np.argmax(prediction,1)
groundTruth_row = np.argmax(test_data[1],1)
CM = confusion_matrix(prediction_row, groundTruth_row)
print(CM)
#-------------------#
#--- Store stuff ---#
#-------------------#
np.savetxt("CM.csv", CM)
np.savetxt("loss.csv", history.history['loss'])
np.savetxt("label_prediction.csv", prediction_row)
np.savetxt("label_groundTruth.csv", groundTruth_row)
np.savetxt("label_IDs.csv", test_data[2], fmt="%s")
np.savetxt("label_predProb.csv", prediction)
#-----------------#
#--- Keras VIS ---#
#-----------------#
#------------------------#
#--- Do vizualization ---#
#------------------------#
from vis.utils import utils
from keras import activations
#--- Find prediction layer and replace it ---#
layer_idx = -1
model.layers[layer_idx].activation = activations.linear
model = utils.apply_modifications(model)
#------------------------#
#--- Load fish images ---#
#------------------------#
import os
from vis.utils import utils
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.cm as cm
from vis.visualization import visualize_cam, overlay
import innvestigate
import innvestigate.utils as iutils
model_wo_softmax = model
LPR_10 = innvestigate.analyzer.relevance_based.relevance_analyzer.LRPAlphaBeta(model_wo_softmax,1,0)

layer_idx = -1
Class_Names = np.array(('0','1','2','3','4','5','6','7','8','9'))
prediction = model.predict(test_data[0])
ground_truth = test_data[1]
#-------------------------#
#--- Visualize results ---#
#-------------------------#
for i in range(0,prediction.shape[0]):
    print("Iteration: ", i)
    pred_row = prediction[i,:]
    index = np.argmax(pred_row)
    prefix= "class_"+str(np.argmax(test_data[1],1)[i])+"_"+ os.path.splitext(test_data[2][i])[0].split("/")[-1] + "_" #Use classname and indices as result file name
    if( ground_truth[i,index] != 1):
        print("Something went wrong")
        prefix=prefix+"F_"
    else:
        print("yes")
    grads = visualize_cam(model, layer_idx, filter_indices=train_generator.class_indices[Class_Names[np.argmax(ground_truth[i,:])]], seed_input=test_data[0][i], backprop_modifier='guided')
    LRP_10_i    = LPR_10.analyze(test_data[0][i].reshape((1,224,224,3)))
    plt.imshow(grads)
    plt.axis('off')
    plt.savefig(prefix+"_grad.png")
    plt.close('all')
    plt.imshow(LRP_10_i[0,:,:,0])
    plt.axis('off')
    plt.savefig(prefix+"_LRP_10.png")
    plt.close('all')
    plt.imshow(test_data[0][i])
    plt.axis('off')
    plt.savefig(prefix+".png")
    plt.close('all')
