{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lagerbock_Image_Classifier",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lbC4AmyNVxg"
      },
      "source": [
        "# Tensorflow CNN implementation based on the example code of the documentation\n",
        "### using opencv and a custom saved model for classification\n",
        "\n",
        "Note: Use Tensorflow 2.4.1  (pip3 install tensorflow==2.4.1)\n",
        "\n",
        "### How to use:\n",
        "- download your model weights folder from your google drive (if you trained using google colab) or make sure your model weights fodler are in the right directory for the \"model_name\"\n",
        "- \"model_name\" has to match your weights folder\n",
        "-  run all cells. \n",
        "- if the device (webcam) can't be opened, try changing the devide_number to either -1, 0, 1 or 2. (This depends if your system has an internal camera or not)\n",
        "- devide_number can also be used to switch between webcams if more than one is available \n",
        "\n",
        "Usefull links: <br>\n",
        "CNN Model is based on: https://www.tensorflow.org/tutorials/images/classification\n"
      ]
    },
    {
      "source": [
        "## Import needed libraries"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR4XfOlGC7zE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import pathlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Setup"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_height = 416\n",
        "img_width = 416\n",
        "dim = (img_width, img_height)\n",
        "model_name = \"model_1_750E32B\"\n",
        "devide_number = -1\n",
        "class_names = ['Hammer', 'Workspace']\n",
        "rotate_frame = True\n",
        "#Load Model\n",
        "model = tf.keras.models.load_model(model_name)"
      ]
    },
    {
      "source": [
        "# Webcam Detection"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(devide_number)\n",
        "if not (cap.isOpened()):\n",
        "    print(\"Could not open video device\")\n",
        "\n",
        "while(True):    \n",
        "    # cap frame by frame   \n",
        "    ret, frame = cap.read()    \n",
        "    \n",
        "    # rotate image (if needed), crop image to 416x416 (training data size)\n",
        "    if (rotate_frame):\n",
        "        frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
        "    y = 100\n",
        "    x = 50\n",
        "    frame = frame[y:y+img_height, x:x+img_width]\n",
        "    cv2.imwrite(\"tmp_hammer.jpg\", frame) #safe img -> keras needs the path\n",
        "\n",
        "    tst_img = pathlib.Path(\"tmp_hammer.jpg\") #load img\n",
        "    img = keras.preprocessing.image.load_img(tst_img, target_size=(img_height, img_width))\n",
        "\n",
        "    img_array = keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "    #print(\"{} {:.2f}\".format(class_names[np.argmax(score)], 100 * np.max(score)))\n",
        "\n",
        "    if class_names[np.argmax(score)] == \"Hammer\":\n",
        "        cv2.putText(frame, \"Hammer in Workspace ({:.2f})\".format(100 * np.max(score)), (10, 40), 1, 1, (0,255,0), 2) \n",
        "    \n",
        "    else:\n",
        "       cv2.putText(frame, \"No Hammer in Workspace ({:.2f})\".format(100 * np.max(score)), (10, 40), 1, 1, (0,0,255), 2)\n",
        "\n",
        "    cv2.imshow('Press q to exit', frame)\n",
        "    #Waits for a user input to quit the application  \n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):    \n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ]
}