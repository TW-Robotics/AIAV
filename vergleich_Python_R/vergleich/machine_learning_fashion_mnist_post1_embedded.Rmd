---
title: Vergleich von verschiedenen KI-Klassifizierungsmethoden am Beispiel des Fashion
  MNIST-Datensatzes in RStudio und Python (Teil 1)
author: "Lars Mehnen"
date: "`r Sys.Date()`"
output:
  word_document: default
  pdf_document: default
  html_document:
    mathjax: default
---
  
In dieser Reihe werden wir verschiedene maschinelle und Deep-Learning-Methoden vergleichen, um Kleidungsklassen anhand von Bildern des Fashion MNIST-Datensatzes zu erstellen bzw. mit dem erstellten Modellen zu klassifizieren. In diesem ersten Beitrag werden wir Daten untersuchen und für die Analyse aufbereiten. Um Ihnen zu zeigen, wie Sie eine der Funktionen von RStudios verwenden, um Python von RStudio aus auszuführen, erstelle ich ein neuronales Netzwerk in Python innerhalb der R-Umgebung. Die Ideen und codes wurden teilweise von dieser [Seite](https://www.r-bloggers.com/2019/11/a-comparison-of-methods-for-predicting-clothing-classes-using-the-fashion-mnist-dataset-in-rstudio-and-python-part-1/) entnommen

```{r setup, setup python path, message = FALSE, warning = FALSE, results = 'hide', echo = FALSE}
# Change python_path according to your Python path (see detailed explanation further in this post)
python_path <- "/usr/bin/python3" 
knitr::opts_chunk$set(echo = TRUE, engine.path = list(python = python_path))
library(reticulate)
use_python(python_path)
```

Zu Beginn setzen wir zunächst einen fixen Random-Seed, um sicherzustellen, dass die Ergebnisse reproduzierbar sind. 
```{r, set seed,  message = FALSE, warning = FALSE, results = 'hide'}
set.seed(815)
```

## Importieren und Exploration der Daten

Das `keras`-Paket enthält die Fashion MNIST-Daten, sodass wir die Daten aus diesem Paket direkt nach der Installation problemlos in RStudio importieren können. 

```{r, load library keras id needed install keras, message = FALSE, warning = FALSE, results = 'hide'}
#library(devtools)
#devtools::install_github("rstudio/keras")
library(keras)        
#install_keras()  
fashion_mnist <- keras::dataset_fashion_mnist()
```

Das resultierende Objekt `fashion_mnist` ist eine Liste, die aus den Unter-Listen `train` und `test`, wobei diese wiederum aus den `x` und `y` Arrays besteht. Um die Größen/Dimensionen der Bilder zu erfahren, wenden wir die Funktion `dim()` rekursiv auf die `fashion_mnist` Liste an. 


```{r, redimension data}
rapply(fashion_mnist, dim)
```

Hier sehen wir, dass das `x`-Array im Trainingsdatensatz `r dim(fashion_mnist$train$x)[3]` Matrizen mit jeweils `r nrow(fashion_mnist$train$x)` Zeilen und `r ncol(fashion_mnist$train$x)` Spalten enthält, oder mit anderen Worten `r nrow(fashion_mnist$train$x)` Bilder mit jeweils `r ncol(fashion_mnist$train$x)` mal `r dim(fashion_mnist$train$x)[3]` Bildpunkten. Das `y`-Array im Trainingsdatensatz enthält `r nrow(fashion_mnist$train$y)` Beschriftungen (auch Label genannt) für jedes der Bilder im `x`-Array der Trainingsdaten. 
Die Testdaten haben eine ähnliche Struktur, enthalten aber nur `r nrow(fashion_mnist$test$x)` Bilder statt `r nrow(fashion_mnist$train$x)`. 
Der Einfachheit halber benennen wir diese Listenelemente in etwas intuitiveres um (wobei `x` jetzt Bilder und `y` Beschriftungen bzw. Label darstellen): 
  
```{r, reshape training/test data-set}
c(train.images, train.labels) %<-% fashion_mnist$train
c(test.images, test.labels) %<-% fashion_mnist$test
```

Jedes Bild wird in einer `r ncol(fashion_mnist$train$x)`x`r dim(fashion_mnist$train$x)[3]`-Matrix erfasst, wobei der [i, j] Eintrag die helligkeit des Pixels auf einer Skala von `r min(fashion_mnist$train$x)` (weiß) bis `r max(fashion_mnist$train$x)` (schwarz) darstellt. Die Labels bestehen aus ganzen Zahlen zwischen null und neun, die jeweils eine ein-eindeutige Kleidungs-klasse darstellen. 
Da die Kategorienamen nicht in den Daten selbst enthalten sind, müssen wir sie manuell hinzufügen. Beachten Sie, dass die Kategorien in den Daten gleich-verteilt angenommen werden. 

```{r , name the coloumns with labels}
cloth_cats = data.frame(category = c('Top', 'Trouser', 'Pullover', 'Dress', 'Coat',  
                                     'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Boot'), 
                        label = seq(0, 9))
```

Um eine Vorstellung davon zu bekommen, was die Daten so alles beinhalten und wie sie aussehen, stellen wir die ersten zehn Bilder der Testdaten als Beispiel dar. Dazu müssen wir die Daten zunächst leicht umformen, damit sie zu `ggplot2` kompatibel werden. Wir wählen die ersten zehn Testbilder aus, konvertieren sie in data.frame's um, benennen die Spalten in die Ziffern 1 bis `r ncol(fashion_mnist$train$x)` um, erstellen eine Variable namens `y` mit den Ziffern 1 bis `r ncol(fashion_mnist$train$x)` und führen dann das ganze wieder nach der Variable `y` zusammen. 
Wir brauchen das Paket `reshape2`, um auf die Funktion `melt()` zugreifen zu können. Dies ergibt eine Datenmatrix (data.frame) von `r ncol(fashion_mnist$train$x)` mal `r ncol(fashion_mnist$train$x)` gleich `r ncol(fashion_mnist$train$x)*ncol(fashion_mnist$train$x)` mal 3 (y Pixel (= y), x Pixel (= variable) und die Helligkeit (= value)). Wir führen das alles zeilenweise mit der Funktion `rbind.fill()` aus dem `plyr`-Paket zusammen und fügen eine Variable `Image` hinzu, bei der es sich um eine eindeutige Zeichenfolge handelt, die `r ncol(fashion_mnist$train$x)*ncol(fashion_mnist$train$x)` Mal für jedes der neun Bilder wiederholt wird, die die Bildnummer und das entsprechende Testset-Label enthält. 

```{r, reshape the data for plotting , message = FALSE, warning = FALSE, results = 'hide'}
library(reshape2)
library(plyr)
subarray <- apply(test.images[1:10, , ], 1, as.data.frame)
subarray <- lapply(subarray, function(df){
  colnames(df) <- seq_len(ncol(df))
  df['y'] <- seq_len(nrow(df))
  df <- melt(df, id = 'y')
  return(df)
})
plotdf <- rbind.fill(subarray)
first_ten_labels <- cloth_cats$category[match(test.labels[1:10], cloth_cats$label)]
first_ten_categories <- paste0('Image ', 1:10, ': ', first_ten_labels)
plotdf['Image'] <- factor(rep(first_ten_categories, unlist(lapply(subarray, nrow))), 
                          levels = unique(first_ten_categories))
```

Dann stellen wir diese ersten zehn Testbilder mit dem Paket `ggplot2`dar. Beachten Sie, dass wir die y-Achse umkehren, da der ursprüngliche Datensatz, die Bilder auf dem Kopf stehend enthält. Wir entfernen desweiteren die Legenden- und Achsenbeschriftungen und ändern etwas die Beschriftungen. 

```{r, plot the first 10 pictures, message = FALSE, warning = FALSE, results = 'hide'}
library(ggplot2)
```

```{r, plot}
ggplot() + 
  geom_raster(data = plotdf, aes(x = variable, y = y, fill = value)) + 
  facet_wrap(~ Image, nrow = 2, ncol = 5) + 
  scale_fill_gradient(low = "white", high = "black", na.value = NA) + 
  theme(aspect.ratio = 1, legend.position = "none") + 
  labs(x = NULL, y = NULL) + 
  scale_x_discrete(breaks = seq(0, 28, 7), expand = c(0, 0)) + 
  scale_y_reverse(breaks = seq(0, 28, 7), expand = c(0, 0))
```

## Daten Vorverarbeitung

Jetzt wird es Zeit für die eher technischen Arbeit, d.h. die Bildklassifizierung (die Label aus den Bilddaten zu schätzen). Zuerst müssen wir unsere Daten wiedermalumformen, um sie von einem mehrdimensionalen Array in eine zweidimensionale Matrix umzuwandeln. Dazu vektorisieren wir jede `r ncol(fashion_mnist$train$x)` x `r ncol(fashion_mnist$train$x)` Matrix in eine Spalte der Länge `r ncol(fashion_mnist$train$x)*ncol(fashion_mnist$train$x)`, und dann verbinden wir die Spalten für alle Bilder übereinander und nehmen schließlich die Transponierte der resultierenden Matrix. Auf diese Weise können wir ein `r ncol(fashion_mnist$train$x)` x `r ncol(fashion_mnist$train$x)` x `r nrow(fashion_mnist$train$x)`-Array in eine `r nrow(fashion_mnist$train$x)` x `r ncol(fashion_mnist$train$x)*ncol(fashion_mnist$train$x)`-Matrix umwandeln. Wir normalisieren die Daten auchnoch, indem wir durch die minimale Helligkeit (schwarz) von `r max(fashion_mnist$train$x)` dividieren. 

```{r, reshape for training/testing}
train.images <- data.frame(t(apply(train.images, 1, c))) / max(fashion_mnist$train$x)
test.images <- data.frame(t(apply(test.images, 1, c))) / max(fashion_mnist$train$x)
```

Wir erstellen nun noch zwei Datensätze, die alle Trainings- und Testdaten (Bilder und Beschriftungen) enthalten. 

```{r, create training and test data-set}
pixs <- 1:ncol(fashion_mnist$train$x)^2
names(train.images) <- names(test.images) <- paste0('pixel', pixs)
train.labels <- data.frame(label = factor(train.labels))
test.labels <- data.frame(label = factor(test.labels))
train.data <- cbind(train.labels, train.images)
test.data <- cbind(test.labels, test.images)
```

## Künstliche Neurale Netze

Beginnen wir nun mit dem Aufbau eines einfachen neuronalen Netzes, um unsere Kleidungsstücke zu klassifizieren. Neuronale Netze enthalten Knoten, die untereinander Werte über Kanten austauschen. Normalerweise ist der Input an jedem Knoten eine Zahl, die gemäß einer nichtlinearen Funktion, der Summe der Inputs mit den dazugehörigen Gewichten der Kanten, transformiert wird, wobei dies die Parameter sind, die während des Trainierens optimiert werden können. 

In diesem Beitrag wir gezeigt, wie künstliche neuronale Netze mit einer unterschiedlichen Anzahl von Hidden-Layer abschneiden, und ich vergleiche diese Netze auch mit einem Convolutional-Neuronal-Net (CNN), das bei visuellen Bildern oft besser geeignet ist. Wir werden sehen wie einige grundlegende Modelle codiert werden, aber es wird hierbei auf weitere optimierungen des Netzes weitgehend verzichtet. Im Wesentlichen kommt es darauf an, dass diese Netzwerk-Parameter / -Architektur weitgehend von der Datenstruktur, Größe und Komplexität der Input-daten abhängen. Je mehr verborgene Schichten hinzugefügt werden, desto komplexere nichtlineare Beziehungen können modelliert werden. 

Obwohl neuronale Netze mit TensorFlow und Keras problemlos in RStudio erstellt werden können, werden wir hier Funktionen von RStudio verwenden, mit der Sie Python in RStudio ausführen können. Dies kann auf zwei Arten erfolgen: Entweder wir wählen „Terminal“ in der Ausgabekonsole in RStudio und führen Python über das Terminal aus, oder wir verwenden die Basisfunktion `system2()`, um Python in RStudio auszuführen. 

Um den Befehl `system2()` zu verwenden, ist es wichtig, zuerst zu prüfen, welche Version von Python verwendet werden soll. Sie können überprüfen, welche Versionen von Python auf Ihrem Computer installiert sind, indem Sie `python --version` in Terminal ausführen. Beachten Sie, dass Sie mit RStudio 1.1 (1.1.383 oder höher) Terminal direkt von RStudio aus auf der Registerkarte „Terminal“ ausführen können. Sie können auch `python3 --version` ausführen, um zu überprüfen, ob Sie Python Version 3 installiert haben. Auf meinem Computer gibt `python3 --version` Python 3.8.10 zurück. Sie können auch `which python` (oder `which python3`, wenn Sie Python Version 3 installiert haben) in Terminal ausführen, wobei hier der Pfad zurückgegeben wird, in dem Ihre Version Python installiert ist. Da wir in diesen Beispielen Python Version 3 verwenden werden, geben wir dies als Pfad für Python in der Funktion `use_python()` aus dem `reticulate` Paket an. Ob die gewünschte Python-Version verwendet wird, können wir mit dem `sys`-Paket von Python überprüfen. Stellen Sie bitte sicher, dass Sie im folgenden Code den Pfad auf die Version von Python ändern, die Sie verwenden möchten, und wo diese Version letztendlich installiert ist. 

```{r, set path for python}
Sys.setenv(RETICULATE_PYTHON = "/usr/bin/python3")
library(reticulate)
use_python("/usr/bin/python3")
```

```{r, import sys}
sys <- import("sys")
sys$version
```

Nachdem wir nun die zu verwendende Version von Python angegeben haben, können wir unser Python-Skript in RStudio mit der Funktion `system2()` ausführen.

```{r, run python script}
python_file <- "simple_neural_network_fashion_mnist.py"
system2("python3", args = c(python_file), stdout = NULL, stderr = "")
```

Ich werde Sie nun Schritt für Schritt durch das im obigen Befehl aufgerufene Skript führen. Zuerst laden wir die erforderlichen Pakete in Python und setzen den Random Seed für die Wiederholbarkeit. 

```{python, step by step example ,  message = FALSE, warning = FALSE}
import numpy as np
np.random.seed(815)
import tensorflow
tensorflow.random.set_seed(9876)
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import keras
from keras.models import Sequential
from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D
from keras.layers import Dropout, SpatialDropout2D

from keras.applications.vgg19 import VGG19
from keras.preprocessing import image
from keras.applications.vgg19 import preprocess_input

from keras.models import Model
from keras.datasets import fashion_mnist

from tensorflow.keras.utils import to_categorical

from keras import models
from keras import layers
from keras import optimizers
```

Wir laden dann die Mode-MNIST-Daten aus „Keras“ und normalisieren die Daten, indem wir sie durch die minimale Helligkeit von 255 dividieren. 

```{python, load mkeras data in python, message = FALSE, warning = FALSE}
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
train_images = train_images / train_images.max()
test_images = test_images / test_images.max()
```

Wir beginnen nun mit der Erstellung eines einfachen neuronalen Netzwerks, das eine Hidden-Layer Schicht enthält. Beachten Sie, dass wir zuerst die Eingabe von `r ncol(fashion_mnist$train$x)` x `r ncol(fashion_mnist$train$x)` Pixeln glätten müssen, da wir hier die nicht transformierten, aber normalisierten Daten verwenden. Wir fügen eine Hidden-Layer Schicht hinzu, die Ausgabe `output = relu(dot(input, kernel) + bias)`, wobei sich die (`relu`) Aktivierungs-Funktion als günstig erwiesen hat. Wir setzen die Anzahl der Knoten auf 128, da dies in unserem Fall ebenfalls günstig ist. Die Anzahl der Knoten könnte im Wesentlichen eine der Zahlen 32, 64, 128, 256 und 512 sein. Der `softmax`-Layer ordnet dann jeder der zehn Bekleidungsklassen, je na Input, Wahrscheinlichkeiten der Zugehörigkeit zu, weshalb es in diesem Layer auch zehn Knoten gibt. 

```{python, create simnple NN, message = FALSE, warning = FALSE}
three_layer_model = Sequential()
three_layer_model.add(Flatten(input_shape = (28, 28)))
three_layer_model.add(Dense(128, activation = 'relu'))
three_layer_model.add(Dense(10, activation = 'softmax'))
```

Nach der Erstellung des neuronalen Netzes kompilieren wir es. Wir spezifizieren `sparse_categorical_crossentropy` als loss function, die gut für kategoriale Mehrklassen geeignet ist. Der Optimierer regelt die Lernrate; `adam` (adaptive moment estimation) ähnelt dem klassischen stochastischen Gradientenabstieg und ist normalerweise eine sichere Wahl für den Optimierer. Wir legen unsere Metrik auf die Genauigkeit (oder den Prozentsatz) korrekt klassifizierter Bilder fest. Im Folgenden passen wir das Modell unter Verwendung von zehn Iterationen durch die Trainingsdaten („Epochen“) an unseren Trainingsdatensatz an. Hier werden 70 % der Daten für das Training und 30 % für die Validierung verwendet. 

```{python, compile NN ,message = FALSE, warning = FALSE}
three_layer_model.compile(loss = 'sparse_categorical_crossentropy', 
                          optimizer = 'adam', metrics = ['acc'])
three_layer_model.fit(train_images, train_labels, epochs = 10, 
                      validation_split = 0.3, verbose = 2)
```

Als nächstes geben wir die Ergebnisse des Modells bzgl. Trainings- und Test-Verluste bzw. -Genauigkeit aus. 

```{python, show accuracy and loss ,message = FALSE, warning = FALSE}
test_loss, test_acc = three_layer_model.evaluate(test_images, test_labels)
print("Model with three layers and ten epochs -- Test loss:", test_loss * 100)
print("Model with three layers and ten epochs -- Test accuracy:", test_acc * 100)
```

Wir können erkennen, dass das neuronale Netz mit einer Hidden-Layer Schicht mit einer Testgenauigkeit von 87.43 % bereits relativ gut abschneidet. Es scheint jedoch, dass wir leicht überangepasst sind (dh das Modell ist zu gut an einen bestimmten Datensatz angepasst und lässt sich daher nicht gut auf andere Datensätze übertragen), da die Genauigkeit des Trainingssatzes (88.92 %) etwas höher ist als die des Testdatensatzes. Es gibt mehrere Möglichkeiten, eine Überanpassung (overfitting) in neuronalen Netzwerken zu vermeiden, z. B. die Vereinfachung unseres Modells durch Reduzierung der Anzahl der verborgenen Schichten und Neuronen, das Hinzufügen von Dropout-Schichten, die zufällig einige der Verbindungen zwischen den Schichten entfernen, und das frühzeitige Stoppen, wenn der Validierungsverlust anzusteingen beginnt. 

```{python, show overfitting, message = FALSE, warning = FALSE}
five_layer_model = Sequential()
five_layer_model.add(Flatten(input_shape = (28, 28)))
five_layer_model.add(Dense(128, activation = 'relu'))
five_layer_model.add(Dense(128, activation = 'relu'))
five_layer_model.add(Dense(128, activation = 'relu'))
five_layer_model.add(Dense(10, activation = 'softmax'))

five_layer_model.compile(loss = 'sparse_categorical_crossentropy', 
                         optimizer = 'adam', metrics = ['acc'])
five_layer_model.fit(train_images, train_labels, epochs = 10, 
                     validation_split = 0.3, verbose = 2)
                     
test_loss, test_acc = five_layer_model.evaluate(test_images, test_labels)
print("Model with five layers and ten epochs -- Test loss:", test_loss * 100)
print("Model with five layers and ten epochs -- Test accuracy:", test_acc * 100)                    
```

Es scheint, dass das Modell mit zwei zusätzlichen Schichten nicht besser abschneidet als das vorherige Modell mit nur einem Hidden-Layer, da sowohl die Trainingsgenauigkeit (87,66 %) als auch die Testsatzgenauigkeit (86,43 %) geringer und der Verlust (38,38) höher ist. Lassen Sie uns nun versuchen, ob das Hinzufügen weiterer fünf Hidden-Layer die Modell-Güte verbessert, oder ob wir bereits erkennen können, dass eine zunehmende Modellkomplexität die Güte nicht mehr wesentlich verbessern kann.

```{python, two more layers are not better, message = FALSE, warning = FALSE}
ten_layer_model = Sequential()
ten_layer_model.add(Flatten(input_shape = (28, 28)))
ten_layer_model.add(Dense(128, activation = 'relu'))
ten_layer_model.add(Dense(128, activation = 'relu'))
ten_layer_model.add(Dense(128, activation = 'relu'))
ten_layer_model.add(Dense(128, activation = 'relu'))
ten_layer_model.add(Dense(128, activation = 'relu'))
ten_layer_model.add(Dense(128, activation = 'relu'))
ten_layer_model.add(Dense(128, activation = 'relu'))
ten_layer_model.add(Dense(128, activation = 'relu'))
ten_layer_model.add(Dense(10, activation = 'softmax'))

ten_layer_model.compile(loss = 'sparse_categorical_crossentropy', 
                        optimizer = 'adam', metrics = ['acc'])
ten_layer_model.fit(train_images, train_labels, epochs = 10, 
                    validation_split = 0.3, verbose = 2)

test_loss, test_acc = ten_layer_model.evaluate(test_images, test_labels)
print("Model with ten layers and ten epochs -- Test loss:", test_loss * 100)
print("Model with ten layers and ten epochs -- Test accuracy:", test_acc * 100)
```

Das Modell mit acht Hidden-Layer schneidet in Bezug auf Trainings- (87.81 %) und Testgenauigkeit (86.89 %) sowie Verlusten (38.36) am besten ab. Dennoch ist der Leistungsunterschied zwischen dem ersten Modell mit nur einem Hidden-Layer und dem aktuellen Modell mit acht Hidden-Layern nur recht gering. Obwohl es scheint, dass wir mit so vielen Hidden-Layer zusätzliche Komplexität modellieren können, welche die Genauigkeit des Modells verbessert, müssen wir uns fragen, ob eine zunehmende Modellkomplexität auf Kosten der Interpretierbarkeit und des rechnerischen Aufwandes diese geringfügige Verbesserung der Genauigkeit und des Verlusts wert ist. Zudem werden wir noch sehen, das diese Genauikeit ebenfalls mit Vorsicht zu genießen ist.

Nachdem wir nun gesehen haben, wie sich die Anzahl der Hidden-Layer auf die Modellleistung auswirkt, wollen wir herausfinden, ob sich eine Erhöhung der Anzahl der Epochen von zehn auf fünfzig (d. h. der Anzahl der Iterationen des Modells durch die Trainingsdaten) positiv auf unser ersten Neuronalen Netzes mit einem Hidden-Layer auswirkt. 

```{python, eight layers do best, message = FALSE, warning = FALSE}
three_layer_model_50_epochs = three_layer_model.fit(train_images, train_labels, 
                                                  epochs = 50, validation_split = 0.3,
                                                  verbose = 2)
                                                  
test_loss, test_acc = three_layer_model.evaluate(test_images, test_labels)
print("Model with three layers and fifty epochs -- Test loss:", test_loss * 100)
print("Model with three layers and fifty epochs -- Test accuracy:", test_acc * 100)
```

Das dreischichtige Modell, das mit fünfzig Epochen trainiert wurde, hat die höchsten Trainings- (89.19 %) und Testgenauigkeiten (88.04 %), die wir bisher gesehen haben. Der Verlust (60.83 %) ist jedoch auch etwa ein Drittel größer als wir zuvor gesehen haben. Darüber hinaus ist das Modell auch weniger zeiteffizient, da die Erhöhung der Genauigkeit unwesentlich ist, aber das Anpassen des Modells aber erheblich länger dauert. Um den Kompromiss zwischen Minimierung des Verlusts und Maximierung der Genauigkeit besser zu verstehen, zeichnen wir den Modellverlust und die Genauigkeit über die Anzahl der Epochen für die Trainings- und Kreuz-Validierungs-Daten auf. 

```{python, show that more epochs do not do much, message = FALSE, warning = FALSE}
# Plot loss as function of epochs
plt.subplot(1, 2, 1)
plt.plot(three_layer_model_50_epochs.history['val_loss'], 'blue')
plt.plot(three_layer_model_50_epochs.history['loss'], 'red')
plt.legend(['Cross-validation', 'Training'], loc = 'upper left')
plt.ylabel('Loss')
plt.xlabel('Epoch')

# Plot accuracy as function of epochs
plt.subplot(1, 2, 2)
plt.plot(three_layer_model_50_epochs.history['val_acc'], 'blue')
plt.plot(three_layer_model_50_epochs.history['acc'], 'red')
plt.ylabel('acc')
plt.xlabel('Epoch')
plt.subplots_adjust(wspace = .35)

# Include plot title and show the plot
plt.suptitle('Model loss and accuracy over epochs for a three-layer neural network')
plt.show()
```

Wir können hier recht gut beobachten, dass für die Trainingsdaten der Verlust auf null sinkt, während die Genauigkeit durch Overfitting auf 1 ansteigt. Aus diesem Grund überprüfen wir auch die Güte des Modells bzgl. Kreuzvalidierungsdaten, bei denen wir beobachten können, dass der Verlust mit der Anzahl der Epochen zunimmt, während die Genauigkeit relativ stabil bleibt. Unter Verwendung dieser Zahl können wir eine möglichst „optimale“ Anzahl von Epochen auswählen, sodass die Genauigkeit maximiert und der Verlust minimiert wird. Wenn wir uns die Genauigkeit der Kreuzvalidierungsdaten ansehen, sehen wir, dass die Genauigkeitsspitze bei etwa 20 Epochen liegt, für die der Verlust etwa 0,4 beträgt. Allerdings werden ähnliche Genauigkeiten, aber viel geringere Verluste und Modellierungszeiten mit etwa 6 und 12 Epochen erreicht, und somit könnten wir uns eher dafür entscheiden, unser Modell mit etwa 6 oder 20 Epochen zu trainieren.

In Bezug auf die Modellausgabe sind die zurückgegebenen klassifizierungs Wahrscheinlichkeiten pro Klasse bzw. Kleidungskategorie. Wir können das Mehrheitsvotum berechnen, indem wir die Klasse nehmen, die das Maximum der vorhergesagten Wahrscheinlichkeiten aller Klassen hat. Wir können die ersten zehn Elemente des `majority_vote` dictionary ausdrucken, welches wir wie folgt erhalten: 

```{python, show crossvalidation (overfitting), message = FALSE, warning = FALSE}
predictions = three_layer_model.predict(test_images)
for i in range(10):
  print("Prediction " + str(i) + ": " + str(np.argmax(np.round(predictions[i]))))
  print("Actual " + str(i) + ": " + str(test_labels[i]))
```

Alle außer der fünften (Nummer 4) Klassifizierung (prediction) sind richtig. In der Fünften wird ein Hemd (Kategorie 6) fälschlicherweise als Oberteil (Kategorie 0) klassifiziert. 

## Convolutional Neural Networks, CNN's

Im folgenden zeigen wir, wie Sie ein konvolutionelles neuronales Netzwerk aufbauen und seine Güte mit den zuvor vorgestellten neuronalen Netzwerken vergleichen, vor allem, weil sich gezeigt hat, dass CNN's im Allgemeinen bei visuellen Bilddaten besser geeignet sind. Was in einem Convolutional Neural Network im Wesentlichen passiert, ist, dass eine kleinere Matrix (die „Filtermatrix“ oder „Kernel“) über die Vollbildmatrix gleitet, sich also Pixel für Pixel bewegt, die Filtermatrix wird mit dem entsprechenden Teil der Vollbildmatrix Matrix-multipliziert, welcher durch die Filtermatrix in diesem Moment abgedeckt wird. Folgend, summieren wir diese Werte und wiederholt dies dann, bis die gesamte Bildmatrix abgedeckt ist.

Da wir unsere Daten für ein Convolutional Neural Network etwas anders aufbereiten müssen, laden wir die Daten neu und formen die Bilder um, um sie zu „glätten“ (flatten). Die letzte „1“ in den Reshape-Dimensionen steht für Graustufen, da wir die Bilder ja in einer Schwarz-Weiß-Skala bereitgestellt bekommen. Wenn wir RGB-Bilder hätten, würden wir die „1“ in eine „3“ für RGB-Werte ändern. 

```{python, CNN , message = FALSE, warning = FALSE}
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
train_images = train_images.reshape(60000, 28, 28, 1)
test_images = test_images.reshape(10000, 28, 28, 1)
```

Wir müssen jetzt erst einmal sicher stellen, dass die Werte der Pixel, die von 0 bis 255 reichen, vom Typ-Float sind und normalisieren dann die Werte wie zuvor. 

```{python, normalize pixel values, message = FALSE, warning = FALSE}
train_images = train_images.astype('float32')
test_images = test_images.astype('float32')
train_images = train_images / train_images.max()
test_images = test_images / test_images.max()
```

Das hier benutzte Convolutional Neural Network kann nicht mit kategorialen Labels umgehen. Daher wandeln wir die Labels in binäre Werte-Vektoren um, wobei alle Vektoren die Länge zehn haben (da es ja zehn Kategorien gibt), eine „1“ an der Index-Stelle der Kategorie und Nullen an den anderen Stellen. Beispielsweise würden die Kategorien 3 und 8 wie folgt codiert [0, 0, 0, 1, 0, 0, 0, 0, 0, 0] und [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]. Diese Transformation wird als „One Hot Encoding“ bezeichnet. 

```{python, one hot encoding for CNN, message = FALSE, warning = FALSE}
train_labels_bin = to_categorical(train_labels)
test_labels_bin = to_categorical(test_labels)
```

Jetzt können wir mit dem Aufbau unseres Convolutional Neural Network beginnen. Die erste Schicht `Conv2D` ist eine Convolution-Schicht, die eine zweidimensionale Matrix von 28 mal 28 Pixeln in Graustufen als Eingabe verwendet. Wir verwenden in dieser Schicht nach wie vor 128 Knoten, da die Menge der Daten nicht wirklich extrem groß ist und wir unser Modell nicht unnötig komplex machen wollen. Die Filtermatrix hat die Größe 3 x 3, was durchaus Standard ist. Wie zuvor verwenden wir die lineare („relu“) Aktivierungsfunktion. Die `MaxPooling2D`-Schicht reduziert die Dimensionalität (und damit die erforderliche Rechenleistung), indem sie das Maximum des Teils des Eingangsbildes ausgibt, der von der Filtermatrix erfasst wird. Die `Flatten`-Schicht glättet einfach das Ergebnis der vorherigen Ebene in einen einzigen langen Vektor. Wie wir zuvor gesehen haben, weist der `softmax`-Layer dann jeder der zehn Kleidungskategorien  Zugehörigkeits-Wahrscheinlichkeiten zu. Beachten Sie, dass wir denselben Optimierer und dieselbe Metrik wie zuvor verwenden, aber dass wir jetzt „categorical_crossentropy“ anstelle von „sparse_categorical_crossentropy“ als Verlustfunktion verwenden. Der Grund dafür ist, dass ersteres für One-Hot-codierte Labels funktioniert, während die andere für kategoriale Labels funktioniert. 

```{python, create CNN, message = FALSE, warning = FALSE}
conv_model = Sequential()
conv_model.add(Conv2D(128, (3, 3), input_shape = (28, 28, 1)))
conv_model.add(Activation('relu'))
conv_model.add(MaxPooling2D(pool_size = (2, 2)))
conv_model.add(Conv2D(128, (3, 3)))
conv_model.add(Activation('relu'))
conv_model.add(MaxPooling2D(pool_size = (2, 2)))
conv_model.add(Flatten())
conv_model.add(Dense(128))
conv_model.add(Dense(10))
conv_model.add(Activation('softmax'))
```

Wir optimieren nun unser Modell an die Trainingsdaten an, wobei wir das Argument `batch_size` gleich der Anzahl der Neuronen in den Convolution-Schicht (= 128) setzen. 

```{python, compile CNN, message = FALSE, warning = FALSE}
conv_model.compile(loss = "categorical_crossentropy", 
                   optimizer = 'adam', metrics = ['acc'])
conv_model.fit(train_images, train_labels_bin, batch_size = 128, 
               epochs = 10, verbose = 2)
            
test_loss, test_acc = conv_model.evaluate(test_images, test_labels_bin)
print("Convolutional model ten epochs -- Test loss:", test_loss * 100)
print("Convolutional model ten epochs -- Test accuracy:", test_acc * 100)
```

Obwohl wir immer noch überangepasst sind, stellen wir fest, dass das Convolutional Neural Network eine bessere Güte als die zuvor gesehenen neuronalen Netze erzielt und eine Trainingssatzgenauigkeit von 91.34 % und eine Testsatzgenauigkeit von 91.34 % sowie einen geringeren Verlust von 27.28 erreicht. Dies war zu erwarten, da sich CNN's bei visuellen Bilddaten als gut erwiesen haben. Mal sehen, ob wir Overfitting reduzieren können, indem wir die Anzahl der Neuronen von 128 auf 64 reduzieren, einen `Dropout`-Layer hinzufügen und ein frühes Stoppen ermöglichen. Beachten Sie, dass die Rate im Dropout-Layer der Prozentsatz der Verbindungen zwischen den Layern ist, die entfernt werden. `SpatialDropout2D` ist eine spezielle Art von `Dropout`-Layer für CNN's, die bestimmte Multiplikationen der Filtermatrix mit Teilen des Originalbildes weg lässt, bevor sie sich über alle Bewegungen der Filtermatrix über das Originalbild hinweg zusammenfasst.

```{python, show that CNN is a bit better even if it is a bit overfitted, message = FALSE, warning = FALSE}
conv_model_reduce_overfit = Sequential()
conv_model_reduce_overfit.add(Conv2D(64, (3, 3), input_shape = (28, 28, 1)))
conv_model_reduce_overfit.add(Activation('relu'))
conv_model_reduce_overfit.add(MaxPooling2D(pool_size = (2, 2)))
conv_model_reduce_overfit.add(Dropout(0.5))
conv_model_reduce_overfit.add(Conv2D(64, (3, 3)))
conv_model_reduce_overfit.add(SpatialDropout2D(0.5))
conv_model_reduce_overfit.add(Activation('relu'))
conv_model_reduce_overfit.add(MaxPooling2D(pool_size = (2, 2)))
conv_model_reduce_overfit.add(Flatten())
conv_model_reduce_overfit.add(Dense(64))
conv_model_reduce_overfit.add(Dropout(0.5))
conv_model_reduce_overfit.add(Dense(10))
conv_model_reduce_overfit.add(Activation('softmax'))
```

Bei der Anpassung unseres Modells ermöglichen wir auch ein frühes Stoppen, um eine Überanpassung möglichst zu verhindern. Anstatt alle angegebenen Epochen zu durchlaufen, stoppen wir die Iterationen durch die Epoche automatisch, sobald festgestellt wird, dass der Validierungsverlust zunimmt. 

```{python, fit model and stop early to reduce overfitting, message = FALSE, warning = FALSE}
conv_model_reduce_overfit.compile(loss = "categorical_crossentropy", 
                   optimizer = 'adam', metrics = ['acc'])
conv_callback = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)
conv_model_reduce_overfit.fit(train_images, train_labels_bin, validation_split = 0.3,
               epochs = 10, verbose = 2, callbacks = [conv_callback], batch_size = 64)

test_loss, test_acc = conv_model_reduce_overfit.evaluate(test_images, test_labels_bin)
print("Convolutional model ten epochs reduced overfit -- Test loss:", test_loss * 100)
print("Convolutional model ten epochs reduced overfit -- Test accuracy:", test_acc * 100)
```

In den Ergebnissen erkennen wir, dass die Trainings- und Testgenauigkeiten zwar abgenommen haben, aber jetzt viel näher an den vorherigen Ergebnissen sind. Die Testgenauigkeit hat nicht wesentlich abgenommen, aber die Trainingsgenauigkeit, was bedeutet, dass Overfitting viel weniger ein Problem darstellt als zuvor. Als Nächstes können wir die ersten zehn Vorhersagen aus dem Modell und die ersten zehn tatsächlichen Labels anzeigen und sie vergleichen. 

```{python, final, message = FALSE, warning = FALSE}
predictions = conv_model_reduce_overfit.predict(test_images)
for i in range(10):
  print("Prediction " + str(i) + ": " + str(np.argmax(np.round(predictions[i]))))
  print("Actual " + str(i) + ": " + str(test_labels[i]))
```
Beim Vergleich dieser Klassifizierung mit den ersten zehn Label im Datensatz stellen wir fest, dass diese ersten zehn richtig sind!