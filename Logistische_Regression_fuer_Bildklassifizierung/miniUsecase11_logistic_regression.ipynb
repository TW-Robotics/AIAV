{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementierung einer logistische Regression zur Erkennung von Werkzeugerkennung am Arbeitsplatz\n",
    "Das Notebook beschreibt die Implementierung einer logistischen Regression für das klassifizieren von Bildern. Genauer gesagt, wollen wir herausfinden ob sich in einem Bild – beziehungsweise einem Kamerastream – ein Hammer befindet oder nicht. \n",
    "\n",
    "\n",
    "## Aufbau:\n",
    "Der Beispielcode ist wie folgt aufgebaut: \n",
    "### Abschnitt 1: Datensatz vorbereiten\n",
    "In diesem Abschnitt werden die notwendigen [Bibliotheken](./requirements.txt) eingebunden sowie die Daten aufbereitet. Es wird ein sogenanntes [Dictonary](https://kapernikov.com/tutorial-image-classification-with-scikit-learn/) erstellt welches die Bilder des Datensatzes verwaltet. Ebenso werden die Bilder in diesem Abschnitt von einer Matrix in einen Vektor umgewandelt. Die Theorie dazu ist in dem logistische Regression [Storyboard](11_Storyboard_logistic_regression.pdf) beschrieben.  \n",
    "\n",
    "### Abschnitt 2: Erstellen des Modells\n",
    "In Abschnitt 2 wird die logistische Regression definiert.  \n",
    "\n",
    "Zum Einsatz kommt hier die [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) Bibliothek welche ermöglicht ein bereits existierendes Model einzubinden und nur die Parameter zu definieren. Dadurch sind features wie Skalieren, PCA oder das Trainieren leicht umgesetzt. Was eine PCA ist und welche Parameter sich auf die LR auswirken sind ebenfalls im [Storyboard](11_Storyboard_logistic_regression.pdf) zu finden. \n",
    "\n",
    "### Abschnitt 3: Webcam Implementierung\n",
    "In diesem Abschnitt wird die Webcam eingebunden mittels [OpenCV](https://opencv.org/). Da ein Video-Stream nur aus vielen hintereinader ablaufenden Bildern besteht, wird einfach jeder Frame (jedes Bild) angeschaut und Klassifiziert. Das Ergebnis wird direkt in das Bild hinein geschrieben und angezeigt. \n",
    "\n",
    "\n",
    "## Ordnerstruktur: \n",
    "1. demo [Ordner]\n",
    "    - webcam_demo.gif\n",
    "    - _demo images_\n",
    "2. Tool_Data [Ordner]\n",
    "(Hier kann der Datensatz geändert werden)\n",
    "    - Hammer _data images_\n",
    "    - Workspace _data images_\n",
    "    \n",
    "3. `image_augmentation.ipynb`\n",
    "(Kann zur Image Augmentation verwendet werden. Muss an den verwendeten Datensatz angepasst werden bevor es ausgeführt wird)\n",
    "\n",
    "4. `miniUsecases11_logistic_regression.ipynb` [Beispielcode]\n",
    "\n",
    "5. `workspace_detection_{width}x{height}px.pkl`\n",
    "\n",
    "6. `requirements.txt`\n",
    "(Notwendige Bibliotheken, kann zum Installieren verwednet werden)\n",
    "\n",
    "7. `11_Storyboard_logistic_regression.pdf`\n",
    "\n",
    "8. `miniUsecases11_logistic_regression.ipynb` [Zusätzliche Funktionen und Visualisierungen]\n",
    "\n",
    "## Resultat: \n",
    "![Abbildung 1](demo/webcam_demo.gif)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abschnitt 1: Datensatz vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importieren der generellen notwendigen Bibliotheken\n",
    "Wir empfehlen die notwendigen Bibliotheken über die [requirements.txt](requirements.txt) Datei zu installieren. Das ermöglicht es, dass automatisch die richtigen Versionen installiert werden. Sollte eine Library nicht vorhanden sein, dann kann die häufig auch mit `pip3 <package-name\\>` nachinstalliert werden. Sind alle libraries vorhanden, entsteht kein Output bei der nächsten Zelle. \n",
    "Im laufe des Notebooks werden weitere Bibliotheken benötigt. Diese werden erst in späteren Zellen aufgerufen um jeweils bei den entsprechenden Codesnipped zu garantieren, dass sie im Workspace geladen sind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4) \n",
    "from sklearn.manifold import Isomap\n",
    "import warnings\n",
    "from scipy.sparse import (spdiags, SparseEfficiencyWarning, csc_matrix,\n",
    "    csr_matrix, isspmatrix, dok_matrix, lil_matrix, bsr_matrix)\n",
    "warnings.simplefilter('ignore',SparseEfficiencyWarning) \n",
    "warnings.simplefilter('ignore',UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verschiedene Einstellungen um das Programm anzupassen\n",
    "\n",
    "data_path: gibt den relativen Pfad zu dem Datensatz (Ordner mit Bildern) an. \n",
    "\n",
    "os.listdir(data_path): Zeigt die Ordner an, welche die Bilder für das Trainieren enthalten sollen. \n",
    "\n",
    "SIZE: definiert die größe des Bildes. Hier kann eingestellt werden wie sehr das Bild \"verkleinert\" werden soll. Ein guter Startpunkt ist meist _<original_image_size/rescaling\\>_ wobei rescaling einfach als Skalar gewählt werden kann. In dem Beispiel verwenden wir ein viertel der Pixellänge. Sprich ein 416x416 Pixelbild ist dann nur mehr 104x104px groß "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Pfad und Bildgröße ändern\n",
    "\n",
    "data_path = os.getcwd() + \"/data\"\n",
    "os.listdir(data_path) #im falle von dem Hammer-Beispiel werden hier Hammer und Workspace angezeigt\n",
    "SIZE = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusatzfunktion für das preperieren der Daten \n",
    "Diese funktion lädt alle Bilder in den Workspace (aus dem definierten Pfad) und macht foglende 2 Aktionen:\n",
    "- Resize: Skaliert die Bilder entsprechend der Vorgabe\n",
    "- Dictionary: Erstellt ein Dictionary mit Labels und Metadata (Datensatz für das Trainieren). Der output wird als _pickle file_ im Workspace abgespeichert.\n",
    "\n",
    "Parameter: \n",
    "- src: gibt den Pfad zu den Daten an\n",
    "- pklname: erstellt den Namen für die Pickle Datei\n",
    "- include: Includiert als String List die beiden Klassen (Hammer, Workspace)\n",
    "- width: gibt die größe der Bilder/Resize an\n",
    "\n",
    "[Tutorial zum Implementieren von Dictionaries](https://kapernikov.com/tutorial-image-classification-with-scikit-learn/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "import joblib\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "# Funktionsdefinition \n",
    "def resize_all(src, pklname, include, width = 150, height=None):\n",
    "    height = height if height is not None else width #ERRORHANDLING\n",
    "    \n",
    "# definiert den Datansatz als Dictionary \n",
    "    data = dict()\n",
    "    data['description'] = 'resized ({0}x{1}) images in rgb'.format(int(width), int(height))\n",
    "    data['label'] = []\n",
    "    data['filename'] = []\n",
    "    data['data'] = []   \n",
    "\n",
    "    pklname = f\"{pklname}_{width}x{height}px.pkl\"\n",
    "\n",
    "    for subdir in os.listdir(src):\n",
    "        if subdir in include:\n",
    "            print(subdir)\n",
    "            current_path = os.path.join(src, subdir)\n",
    " \n",
    " # itteriert über alle Bilder im Datensatz \n",
    "            for file in os.listdir(current_path):\n",
    "                if file[-3:] in {'jpg', 'png'}:\n",
    "                    im = imread(os.path.join(current_path, file))\n",
    "                    im = resize(im, (width, height)) #[:,:,::-1]\n",
    "                    data['label'].append(subdir[:-4])\n",
    "                    data['filename'].append(file)\n",
    "                    data['data'].append(im)\n",
    " \n",
    "# erstellt die Pickle file\n",
    "        joblib.dump(data, pklname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatieren des Datensatzes\n",
    "Hier wird die Hilfsfunktion aufgerufen, die für das erstellen des Datensatzes notwendig ist. Ebenso werden hier die Parameter übergeben. Zu beachten ist, dass hier nur _.jpg_ und _.png_ Bilder verarbeitet werden können. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pullover\n",
      "Dress\n"
     ]
    }
   ],
   "source": [
    "base_name = 'Fashion-MNIST'   # Name für die Beschreibung des Datensatzes\n",
    "width = SIZE                        # Definierte Bildgröße übergeben (Zelle 2)\n",
    "include = {'Dress', 'Pullover'}   # Ordner angeben\n",
    " \n",
    "#FUNCTION CALL\n",
    "resize_all(src=data_path, pklname=base_name, width=width, include=include) # Funktionsaufruf für das erstellen der pkl-Datei "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informationen vom Datensatz\n",
    "anbei werden bei korrektem erstellen des Dictionarys die Informationen dazu angezeigt. Diese werden über die Pickle Datei ausgelesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der gefundenen Daten:  11976\n",
      "keys:  ['description', 'label', 'filename', 'data']\n",
      "Beschreibung:  resized (28x28) images in rgb\n",
      "Bild Form  (28, 28)\n",
      "Labels: ['D' 'Pull']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'Pull': 5991, 'D': 5985})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    " \n",
    "data = joblib.load(f'{base_name}_{width}x{width}px.pkl')    # Laden der Datei\n",
    "print('Anzahl der gefundenen Daten: ', len(data['data']))   \n",
    "print('keys: ', list(data.keys()))                          # Zeigt die einzelnen Komponenten  \n",
    "print('Beschreibung: ', data['description'])                \n",
    "print('Bild Form ', data['data'][0].shape)                  # Format anzeigen. Nützlich für das Reshapen nachher\n",
    "print('Labels:', np.unique(data['label']))                  # Labels für die Klassifizierung\n",
    "Counter(data['label'])                                      # Aufteilung anzeigen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensatz Beispiel der beiden Klassen\n",
    "Folgende Zelle lädt jeweils ein Bild/Klasse. Sollten hier nicht erwartete Bilder erscheinen muss der Datensatz überprüft werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = np.unique(data['label'])           # Labels auslesen\n",
    "\n",
    "\n",
    "# Matplot handling um Achsen zu erstellen\n",
    "fig, axes = plt.subplots(1, len(labels))    # Plot definieren\n",
    "fig.set_size_inches(15,4)                   # Größe\n",
    "fig.tight_layout() \n",
    "\n",
    "# Generiert einen Plot mit einem Bild aus jeder Klasse\n",
    "for ax, label in zip(axes, labels):\n",
    "    idx = data['label'].index(label)\n",
    "    ax.imshow(data['data'][idx])\n",
    "    ax.axis('off')\n",
    "    ax.set_title(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensatz umformen\n",
    "Die derzeitige Form eines eingelesenen Bildes ist <index, breite, höhe, schichten> mit index für die Anzahl der Elemente, Breite/Höhe gibt die Bildgröße in Pixel an und Schichten beschreibt die Art des Bildes (3 = RGB)\n",
    "\n",
    "Um eine Klassifikation durchzuführen benötigt das System einen Vektor mit maximal 2 Dimensionen. Wir wollen einen Vektor mit <index, pixel_vektor> wobei index gleich bleibt um mit den Labels übereinzustimmen. Der pixel_vektor wird aus den restlichen Ebenen gebildet, um einen 1*n Vektor zu erhalten.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Form: (11976, 28, 28)\n",
      "Umgeformter Datensatz der Form: (11976, 784)\n",
      "Der Index muss mit der Labels größe Übereinstimmen. \n",
      "Labels größe: (11976,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data['data'])                                      # Einlesen der Bilder\n",
    "print(\"Original Form: {}\".format(X.shape))                      \n",
    "x = X.reshape(X.shape[0], X.shape[1]* X.shape[2])   # Umformen auf die beschriebene Größe\n",
    "print(\"Umgeformter Datensatz der Form: {}\".format(x.shape))\n",
    "\n",
    "y = np.array(data['label'])                                     # Einlesen der Labels\n",
    "print(\"Der Index muss mit der Labels größe Übereinstimmen. \\nLabels größe: {}\".format(y.shape)) #Abgleichen ob die Form übereinstimmt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abschnitt 2: Erstellen des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Im folgenden Abschnitt wird das Logistic Regression Model erstellt \n",
    "Hier wird der Abblauf wie folgt durchgeführt:\n",
    "- (1)Datensatz aufteilen: Hier wird der Datensatz in einen Trainingsanteil und in einen Testanteil Aufgeteilt um zu überprüfen ob das Model in die richtige Richtung trainiert\n",
    "- (2)Skalieren: Standardisierung von Merkmalen durch Entfernen des Mittelwerts und Skalierung auf Einheitsvarianz\n",
    "- (3)PCA: Principal component analysis für eine lineare Dimensionalitätsreduktion des Eingangsvektors. (\"Pixelreduktion\" unserer Trainingsdaten)\n",
    "- (4)Model definieren \n",
    "- (5)trainieren\n",
    "- (6)Test Prediction\n",
    "- (7)Auswertung \n",
    "\n",
    "\n",
    "\n",
    "Zum Einsatz kommt hier die sklearn Bibliothek welche ermöglicht ein bereits existierendes Model einzubinden und nur die Parameter zu definieren. Dadurch sind features wie Skalieren, PCA oder das Trainieren leicht umgesetzt. \n",
    "\n",
    "Weitere [Dokumentation](https://scikit-learn.org/0.16/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "classes: ['D' 'Pull']\n",
      "Score training Data: 0.9812358777876019\n",
      "Score test Data: 0.9760712298274903\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Libraries\n",
    "from cv2 import data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "########\n",
    "# Data #\n",
    "\n",
    "# (1)Aufteilen des Datensatzes\n",
    "x_train, x_test, y_train, y_test =\\\n",
    "    train_test_split(x, y, test_size=0.15, random_state=0)\n",
    "\n",
    "# (2) Skalieren\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# (3) PCA\n",
    "pca = PCA(.95) # verwendet 95% der Komponenten\n",
    "pca.fit(x_train)\n",
    "pca.n_components_\n",
    "print(pca.n_components_) #ausgabe der Komponenten an der Konsole\n",
    "x_train = pca.transform(x_train)\n",
    "x_test = pca.transform(x_test)\n",
    "\n",
    "#######################\n",
    "# (4) Model erstellen #\n",
    "model = LogisticRegression(solver='saga', C=0.5, multi_class='ovr',random_state=0, max_iter=10000) \n",
    "    # solver: {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "    # C: Kehrwert der Regularisierungsstärke; optional; default = 1.0; kleiner Wert entspricht stärkkerer Regularisierung\n",
    "    # random_state: (int) seed für das \"zufällige\" mischen der Daten\n",
    "    # multi_class: \"ovr\" oder \"multinomial\"; ovr=binary Problem; multinomial=multinomial loss fit (funktioniert nur mit \"lbfgs\" solver)\n",
    "    # \n",
    "    # more info: https://scikit-learn.org/0.16/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\n",
    "    #\n",
    "\n",
    "# (5) Trainieren des Models \n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "##############\n",
    "# (6-7)Evaluation #\n",
    "# get corresponding prediction \n",
    "y_pred = model.predict(x_test) # (6) Test Prediction\n",
    "# (7)\n",
    "#print(\"Model Parameter: {}\\n\".format(model.get_params(True)))\n",
    "print(\"classes: {}\".format(model.classes_))\n",
    "print(\"Score training Data: {}\".format(model.score(x_train, y_train)))\n",
    "print(\"Score test Data: {}\".format(model.score(x_test, y_test)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auflistung der PCA Komponenten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es werden 180 PCA Punkte verwendet\n"
     ]
    }
   ],
   "source": [
    "print(\"Es werden {} PCA Punkte verwendet\".format(pca.n_components_)) #anzahl an features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Zelle für das Ausführen der Prediction für 2 Bilder\n",
    "Die folgende Zelle nimmt nun das trainierte Modell her und führt eine Prediction anhand zwei demo Bilder durch. Diese sind in dem Demo Ordner hinterlegt. Ziel ist es einmal einen Workspace und einmal einen Hammer zu erkennen. Ist dies nicht der Fall, ist es wahrscheinlich keine gute Vorraussetzung für die Webcam-Implementation und die Modell-Parameter sollten überarbeitet werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "Hammer Example:\n",
      "Class: D\t with Probability of: \t[0.99623029 0.00376971] \n",
      "Workspace Example:\n",
      "Class: Pull\t with Probability of: \t[3.35831137e-05 9.99966417e-01] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Einlesen und definieren der Bilder\n",
    "demo1 = \"demo/001.png\"\n",
    "demo2 = \"demo/002.png\"\n",
    "width = SIZE\n",
    "height = SIZE\n",
    "\n",
    "# Vorbereiten der Bilder\n",
    "im1 = imread(demo1)\n",
    "im1 = resize(im1, (width, height))\n",
    "im1 = im1.reshape(1 ,-1)\n",
    "im1 = scaler.transform(im1)\n",
    "im1 = pca.transform(im1)\n",
    "\n",
    "im2 = imread(demo2)\n",
    "im2 = resize(im2, (width, height))\n",
    "im2 = im2.reshape(1 ,-1)\n",
    "im2 = scaler.transform(im2)\n",
    "im2 = pca.transform(im2)\n",
    "\n",
    "\n",
    "# Prediction und Ausgabe für das erste Bild\n",
    "y_new_prob  = model.predict_proba(im1)\n",
    "y_new  = model.predict(im1)\n",
    "print(\"Hammer Example:\")\n",
    "print(\"Class: {}\\t with Probability of: \\t{} \".format(y_new[0], y_new_prob[0]))\n",
    "\n",
    "# Prediction und Ausgabe für das zweite Bild\n",
    "y_new_prob  = model.predict_proba(im2)\n",
    "y_new  = model.predict(im2)\n",
    "print(\"Workspace Example:\")\n",
    "print(\"Class: {}\\t with Probability of: \\t{} \".format(y_new[0], y_new_prob[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abschnitt 3: Webcam Implementierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ausführung der Live erkennung\n",
    "In der folgenden Zelle wird ein Kamerastream geöffnet und Frame für Frame eine Prediction durchgeführt. so wie es in dem Demo example auch passiert ist. Der unterschied hier ist lediglich, dass die Bilder nicht eingelesen werden über vorhandene Daten sondern dynamisch über die Kamera \"generiert\" werden.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************\n",
      "Example Image: 18\n",
      "Pullover\n",
      "99.95%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#libraries\n",
    "from skimage.transform import resize\n",
    "from sklearn.decomposition import PCA\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "cv2.namedWindow('Prediction | press q to exit', 0)\n",
    "i = 0\n",
    "for filename in os.listdir(\"demo\"):\n",
    "    img = cv2.imread(os.path.join(\"demo/\",filename), 0)\n",
    "    img = resize(img, (width, height))\n",
    "    if img is None:\n",
    "        print(os.path.join(\"demo/\",filename))\n",
    "        break\n",
    "    else: \n",
    "        # Bild aus einer Matrix in einen Vektor umformen \n",
    "        image = img.reshape(1 ,-1)\n",
    "\n",
    "        # Bild an das Modell anpassen (Skalieren und PCA anwenden)\n",
    "        image = scaler.transform(image)\n",
    "        image = pca.transform(image)\n",
    "\n",
    "        #Predict \n",
    "        y_new_prob  = model.predict_proba(image)\n",
    "        y_new  = model.predict(image)\n",
    "\n",
    "        # Wahrscheinlichkeit des Bildes (bei einer Klassifizierung) in Prozent umrechnen\n",
    "        prob = y_new_prob[0]*100\n",
    "\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(\"***************\")\n",
    "        i = i+1\n",
    "        print(\"Example Image: {}\".format(i))\n",
    "        #Auswertung für die \"live\" Darstellung\n",
    "        if (y_new == \"D\"):\n",
    "            print(\"Dress\")\n",
    "            print(\"{:.2f}%\".format(prob[0]))\n",
    "        elif (y_new == \"Pull\"): \n",
    "\n",
    "            print(\"Pullover\")\n",
    "            print(\"{:.2f}%\".format(prob[1]))\n",
    "        else:\n",
    "            print(\"Unknown Class: ({})\".format(y_new))\n",
    "\n",
    "        \n",
    "        #Ausgabe \n",
    "        cv2.imshow('Prediction | press q to exit', img)\n",
    "        #User Input für das beenden des Darstellen  \n",
    "        if cv2.waitKey(1000) & 0xFF == ord('q'):    \n",
    "            break\n",
    "\n",
    "\n",
    "# Stream schließen und Window Handling\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
