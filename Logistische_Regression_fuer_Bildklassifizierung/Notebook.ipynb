{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Der simpelste Weg Kleidungsstücke zu klassifizieren: Implementierung einer Logistic Regression\n",
    "Das Notebook beschreibt die Implementierung einer logistischen Regression (LR) für das Klassifizieren von Bildern. Genauer gesagt, wollen wir herausfinden, ob sich in einem Bild ein Kleid oder ein Pullover befindet. \n",
    "\n",
    "\n",
    "## Aufbau:\n",
    "Der Beispielcode ist wie folgt aufgebaut: \n",
    "### Abschnitt 1: Datensatz vorbereiten\n",
    "In diesem Abschnitt werden die notwendigen [Bibliotheken](./requirements.txt) eingebunden sowie die Daten aufbereitet. Es wird ein sogenanntes [Dictonary](https://kapernikov.com/tutorial-image-classification-with-scikit-learn/) erstellt, welches die Bilder des Datensatzes verwaltet. Ebenso werden die Bilder in diesem Abschnitt von einer Matrix in einen Vektor umgewandelt. \n",
    "\n",
    "### Abschnitt 2: Erstellen des Modells\n",
    "In Abschnitt 2 wird die logistische Regression definiert.  \n",
    "\n",
    "Zum Einsatz kommt hier die [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) Bibliothek, welche es ermöglicht, ein bereits existierendes Model einzubinden und nur die Parameter zu definieren. Dadurch sind Features wie Skalieren, PCA oder das Trainieren leicht umgesetzt. Was eine PCA ist und welche Parameter sich auf die LR auswirken sind ebenfalls im [Storyboard](11_Storyboard_logistic_regression.pdf) zu finden. \n",
    "\n",
    "### Abschnitt 3: Webcam Implementierung\n",
    "In diesem Abschnitt wird die logistische Regression getestet. Im Demo Ordner sind 24 Bilder abgelegt, welche nicht für das Trainieren oder Testen eingesetzt wurden. Das Modell soll diese Bilder klassifizieren.  \n",
    "\n",
    "\n",
    "## Ordnerstruktur: \n",
    "1. demo [Ordner]\n",
    "    - _demo images_\n",
    "2. data [Ordner]\n",
    "(Hier kann der Datensatz geändert werden)\n",
    "    - Dress _data images_\n",
    "    - Pullover _data images_\n",
    "3. eigenfaces [Ordner]\n",
    "    - Top 10 Eigenfaces der PCA\n",
    "\n",
    "4. `miniUsecases11_logistic_regression.ipynb` [Beispielcode]\n",
    "\n",
    "5. `Fashion_MNIST{width}x{height}px.pkl`\n",
    "\n",
    "6. `requirements.txt`\n",
    "(Notwendige Bibliotheken, kann zum Installieren verwednet werden)\n",
    "\n",
    "7. `11_Storyboard_logistic_regression.pdf`\n",
    "\n",
    "\n",
    "## Resultat: \n",
    "![Abbildung 1](demo.gif)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abschnitt 1: Datensatz vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importieren der generellen notwendigen Bibliotheken\n",
    "Wir empfehlen Ihnen, die für die Applikation notwendigen Bibliotheken mittels der [requirements.txt](./requirements.txt) Datei zu installieren, um die automatische Installation der richtigen Bibliotheksversionen zu garantieren. Sollte eine Bibliothek nicht vorhanden sein, dann kann sie auch mit `pip3 <package-name\\>` nachinstalliert werden.\n",
    "\n",
    "Sind alle Bibliotheken vorhanden, entsteht kein Output bei der nächsten Zelle. Im laufe des Notebooks werden weitere Bibliotheken benötigt. Diese werden erst in späteren Zellen aufgerufen, um jeweils bei den entsprechenden Codesnippets zu garantieren, dass sie im Workspace geladen sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4) \n",
    "from sklearn.manifold import Isomap\n",
    "import warnings\n",
    "from scipy.sparse import (spdiags, SparseEfficiencyWarning, csc_matrix,\n",
    "    csr_matrix, isspmatrix, dok_matrix, lil_matrix, bsr_matrix)\n",
    "warnings.simplefilter('ignore',SparseEfficiencyWarning) \n",
    "warnings.simplefilter('ignore',UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verschiedene Einstellungen um das Programm anzupassen\n",
    "\n",
    "data_path: Gibt den relativen Pfad zum Datensatz (Ordner mit Bildern) an. \n",
    "\n",
    "os.listdir(data_path): Zeigt die Ordner an, welche die Bilder für das Training enthalten sollen. \n",
    "\n",
    "SIZE: Gibt an, wie groß das Bild ist. In dem Fall vom MNIST Datensatz haben wir immer 28x28pxl Bilder, somit ist SIZE=28. Sollten größere Bilder verwendet werden, kann hier auch angegeben werden, um wie viel sich ein Bild verkleinern soll. Beispielsweise kann ein 416x416 Bild mit SIZE=416/4 angegeben werden. Daraufhin wird im Laufe des Notebooks das Bild auf 104x104pxl reduziert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Pfad und Bildgröße ändern\n",
    "\n",
    "data_path = os.getcwd() + \"/data\"\n",
    "os.listdir(data_path)\n",
    "SIZE = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusatzfunktion für das Präparieren der Daten \n",
    "Diese Funktion lädt alle Bilder in den Workspace (aus dem definierten Pfad) und führt die beiden folgenden Aktionen aus:\n",
    "- Resize: Skaliert die Bilder entsprechend der Vorgabe\n",
    "- Dictionary: Erstellt ein Dictionary mit Labels und Metadata (Datensatz für das Trainieren). Der Output wird als _pickle file_ im Workspace abgespeichert.\n",
    "\n",
    "Parameter: \n",
    "- src: Gibt den Pfad zu den Daten an\n",
    "- pklname: Erstellt den Namen für die Pickle Datei\n",
    "- include: Inkludiert als String List die beiden Klassen (Dress, Pullover)\n",
    "- width: Gibt die Größe der Bilder/Resize an\n",
    "\n",
    "[Tutorial zum Implementieren von Dictionaries](https://kapernikov.com/tutorial-image-classification-with-scikit-learn/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "import joblib\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "# Funktionsdefinition \n",
    "def resize_all(src, pklname, include, width = 150, height=None):\n",
    "    height = height if height is not None else width #ERRORHANDLING\n",
    "    \n",
    "# definiert den Datansatz als Dictionary \n",
    "    data = dict()\n",
    "    data['description'] = 'resized ({0}x{1}) images in rgb'.format(int(width), int(height))\n",
    "    data['label'] = []\n",
    "    data['filename'] = []\n",
    "    data['data'] = []   \n",
    "\n",
    "    pklname = f\"{pklname}_{width}x{height}px.pkl\"\n",
    "\n",
    "    for subdir in os.listdir(src):\n",
    "        if subdir in include:\n",
    "            print(subdir)\n",
    "            current_path = os.path.join(src, subdir)\n",
    " \n",
    " # itteriert über alle Bilder im Datensatz \n",
    "            for file in os.listdir(current_path):\n",
    "                if file[-3:] in {'jpg', 'png'}:\n",
    "                    im = imread(os.path.join(current_path, file))\n",
    "                    im = resize(im, (width, height)) #[:,:,::-1]\n",
    "                    data['label'].append(subdir[:-4])\n",
    "                    data['filename'].append(file)\n",
    "                    data['data'].append(im)\n",
    " \n",
    "# erstellt die Pickle file\n",
    "        joblib.dump(data, pklname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatieren des Datensatzes\n",
    "Hier wird die Hilfsfunktion aufgerufen, die für das Erstellen des Datensatzes notwendig ist. Ebenso werden hier die Parameter übergeben. Zu beachten ist, dass hier nur _.jpg_ und _.png_ Bilder verarbeitet werden können. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pullover\n",
      "Dress\n"
     ]
    }
   ],
   "source": [
    "base_name = 'Fashion-MNIST'   # Name für die Beschreibung des Datensatzes\n",
    "width = SIZE                        # Definierte Bildgröße übergeben (Zelle 2)\n",
    "height = SIZE\n",
    "include = {'Dress', 'Pullover'}   # Ordner angeben\n",
    " \n",
    "#FUNCTION CALL\n",
    "resize_all(src=data_path, pklname=base_name, width=width, include=include) # Funktionsaufruf für das erstellen der pkl-Datei "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informationen vom Datensatz\n",
    "Anbei werden bei korrektem Erstellen des Dictionarys die Informationen dazu angezeigt. Diese werden über die Pickle Datei ausgelesen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der gefundenen Daten:  11976\n",
      "keys:  ['description', 'label', 'filename', 'data']\n",
      "Beschreibung:  resized (28x28) images in rgb\n",
      "Bild Form  (28, 28)\n",
      "Labels: ['D' 'Pull']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'Pull': 5991, 'D': 5985})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    " \n",
    "data = joblib.load(f'{base_name}_{width}x{width}px.pkl')    # Laden der Datei\n",
    "print('Anzahl der gefundenen Daten: ', len(data['data']))   \n",
    "print('keys: ', list(data.keys()))                          # Zeigt die einzelnen Komponenten  \n",
    "print('Beschreibung: ', data['description'])                \n",
    "print('Bild Form ', data['data'][0].shape)                  # Format anzeigen. Nützlich für das Reshapen nachher\n",
    "print('Labels:', np.unique(data['label']))                  # Labels für die Klassifizierung\n",
    "Counter(data['label'])                                      # Aufteilung anzeigen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensatz Beispiel der beiden Klassen\n",
    "Folgende Zelle lädt jeweils ein Bild/Klasse. Sollten hier nicht erwartete Bilder erscheinen, muss der Datensatz überprüft werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = np.unique(data['label'])           # Labels auslesen\n",
    "\n",
    "\n",
    "# Matplot handling um Achsen zu erstellen\n",
    "fig, axes = plt.subplots(1, len(labels))    # Plot definieren\n",
    "fig.set_size_inches(15,4)                   # Größe\n",
    "fig.tight_layout() \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Generiert einen Plot mit einem Bild aus jeder Klasse\n",
    "for ax, label in zip(axes, labels):\n",
    "    idx = data['label'].index(label)\n",
    "    ax.imshow( data['data'][idx] )\n",
    "    ax.axis('off')\n",
    "    ax.set_title(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensatz umformen\n",
    "\n",
    "Die derzeitige Form eines eingelesenen Bildes ist _<index, breite, höhe, schichten>_, mit _index_ für die Anzahl der Elemente, _breite_/_höhe_ gibt die Bildgröße in Pixel an und _schichten_ beschreibt die Art des Bildes (3 = RGB Bild). In unserem Fall haben wir nur Graustufenbilder, weshalb die Form auf <index, breite, höhe> reduziert wird.\n",
    "\n",
    "Um eine Klassifikation durchzuführen, benötigt das System einen Vektor mit maximal 2 Dimensionen. Wir wollen einen Vektor mit _<index, pixel_vektor>_ erstellen, wobei _index_ gleich bleibt, um mit den Labels übereinzustimmen. Der _pixel_vektor_ wird aus den restlichen Ebenen gebildet, um einen 1*n Vektor zu erhalten.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Form: (11976, 28, 28)\n",
      "Umgeformter Datensatz der Form: (11976, 784)\n",
      "Der Index muss mit der Labels größe Übereinstimmen. \n",
      "Labels größe: (11976,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data['data'])                                      # Einlesen der Bilder\n",
    "print(\"Original Form: {}\".format(X.shape))                      \n",
    "x = X.reshape(X.shape[0], X.shape[1]* X.shape[2])   # Umformen auf die beschriebene Größe\n",
    "print(\"Umgeformter Datensatz der Form: {}\".format(x.shape))\n",
    "\n",
    "y = np.array(data['label'])                                     # Einlesen der Labels\n",
    "print(\"Der Index muss mit der Labels größe Übereinstimmen. \\nLabels größe: {}\".format(y.shape)) #Abgleichen ob die Form übereinstimmt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abschnitt 2: Erstellen des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell\n",
    "\n",
    "Im folgenden Abschnitt wird das Logistic Regression Model erstellt \n",
    "Hier wird der Ablauf wie folgt durchgeführt:\n",
    "- (1) Datensatz aufteilen: Hier wird der Datensatz in einen Trainingsanteil und in einen Testanteil aufgeteilt, um zu überprüfen, ob das Modell in die richtige Richtung trainiert\n",
    "- (2) Skalieren: Standardisierung von Merkmalen durch Entfernen des Mittelwerts und Skalierung auf Einheitsvarianz\n",
    "- (3) PCA: Principal component analysis für eine lineare Dimensionalitätsreduktion des Eingangsvektors. (\"Pixelreduktion\" unserer Trainingsdaten)\n",
    "- (4) Model definieren \n",
    "- (5) trainieren\n",
    "- (6) Test Prediction\n",
    "- (7) Auswertung \n",
    "\n",
    "\n",
    "\n",
    "Zum Einsatz kommt hier die sklearn Bibliothek welche ermöglicht ein bereits existierendes Model einzubinden und nur die Parameter zu definieren. Dadurch sind features wie Skalieren, PCA oder das Trainieren leicht umgesetzt. \n",
    "\n",
    "Weitere [Dokumentation](https://scikit-learn.org/0.16/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Components: \n",
      "10\n",
      "classes: ['D' 'Pull']\n",
      "Score training Data: 0.971804695942627\n",
      "Score test Data: 0.9777406789092933\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Libraries\n",
    "from cv2 import data\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "########\n",
    "# Data #\n",
    "\n",
    "# (1)Aufteilen des Datensatzes\n",
    "x_train, x_test, y_train, y_test =\\\n",
    "    train_test_split(x, y, test_size=0.15, random_state=0)\n",
    "\n",
    "# (2) Skalieren\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# (3) PCA\n",
    "#pca = PCA(.95) # verwendet 95% der Komponenten\n",
    "pca = PCA(10) # verwendet 95% der Komponenten\n",
    "pca.fit(x_train)\n",
    "pca.n_components_\n",
    "print(\"PCA Components: \")\n",
    "print(pca.n_components_) #ausgabe der Komponenten an der Konsole\n",
    "x_train = pca.transform(x_train)\n",
    "x_test = pca.transform(x_test)\n",
    "\n",
    "#######################\n",
    "# (4) Model erstellen #\n",
    "model = LogisticRegression(solver='saga', C=0.5, multi_class='ovr',random_state=0, max_iter=10000) \n",
    "    # solver: {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "    # C: Kehrwert der Regularisierungsstärke; optional; default = 1.0; kleiner Wert entspricht stärkkerer Regularisierung\n",
    "    # random_state: (int) seed für das \"zufällige\" mischen der Daten\n",
    "    # multi_class: \"ovr\" oder \"multinomial\"; ovr=binary Problem; multinomial=multinomial loss fit (funktioniert nur mit \"lbfgs\" solver)\n",
    "    # \n",
    "    # more info: https://scikit-learn.org/0.16/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\n",
    "    #\n",
    "\n",
    "# (5) Trainieren des Models \n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "##############\n",
    "# (6-7)Evaluation #\n",
    "# get corresponding prediction \n",
    "y_pred = model.predict(x_test) # (6) Test Prediction\n",
    "# (7)\n",
    "#print(\"Model Parameter: {}\\n\".format(model.get_params(True)))\n",
    "print(\"classes: {}\".format(model.classes_))\n",
    "print(\"Score training Data: {}\".format(model.score(x_train, y_train)))\n",
    "print(\"Score test Data: {}\".format(model.score(x_test, y_test)))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie schon im Storyboard angesprochen, können wir uns die wichtigsten PCA Merkmale ausgeben lassen. Die folgende Zelle macht genau das. Es werden aus der PCA die 10 wichtigsten Merkmale herausgenommen und als Bild dargestellt. Das Ergebnis ist im Ordner \"eigenfaces\" zu finden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP 10 eigenfaces \n",
    "\n",
    "nbr_eigenfaces = 10\n",
    "\n",
    "eigenfaces = pca.components_[:nbr_eigenfaces]\n",
    "eigenfaces = eigenfaces.reshape((nbr_eigenfaces, int(SIZE), int(SIZE)))\n",
    "\n",
    "for i in range(nbr_eigenfaces):\n",
    "\n",
    "    min_ = np.amin(eigenfaces[i])\n",
    "    max_ = np.amax(eigenfaces[i])\n",
    "\n",
    "    tmp = ((eigenfaces[i] - min_) / (max_-min_)) * 255\n",
    "\n",
    "    filename = \"eigenfaces/eigenface\" + str(i) + \".png\"  \n",
    "    cv2.imwrite(filename, tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auflistung der PCA Komponenten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es werden 10 PCA Punkte verwendet\n"
     ]
    }
   ],
   "source": [
    "print(\"Es werden {} PCA Punkte verwendet\".format(pca.n_components_)) #anzahl an features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abschnitt 3: Testen des Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************\n",
      "Example Image: 24\n",
      "Dress\n",
      "100.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#libraries\n",
    "from skimage.transform import resize\n",
    "from sklearn.decomposition import PCA\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "cv2.namedWindow('Prediction | press q to exit', 0)\n",
    "i = 0\n",
    "for filename in os.listdir(\"demo\"):\n",
    "    img = cv2.imread(os.path.join(\"demo/\",filename), 0)\n",
    "    #img = resize(img, (width, height))\n",
    "    \n",
    "    if img is None:\n",
    "        print(os.path.join(\"demo/\",filename))\n",
    "        break\n",
    "    else: \n",
    "        # Bild aus einer Matrix in einen Vektor umformen \n",
    "        image = img.reshape(1 ,-1)\n",
    "\n",
    "        # Bild an das Modell anpassen (Skalieren und PCA anwenden)\n",
    "        image = scaler.transform(image)\n",
    "        image = pca.transform(image)\n",
    "\n",
    "        #Predict \n",
    "        y_new_prob  = model.predict_proba(image)\n",
    "        y_new  = model.predict(image)\n",
    "\n",
    "        # Wahrscheinlichkeit des Bildes (bei einer Klassifizierung) in Prozent umrechnen\n",
    "        prob = y_new_prob[0]*100\n",
    "\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(\"***************\")\n",
    "        i = i+1\n",
    "        print(\"Example Image: {}\".format(i))\n",
    "        #Auswertung für die \"live\" Darstellung\n",
    "        if (y_new == \"D\"):\n",
    "            print(\"Dress\")\n",
    "            print(\"{:.2f}%\".format(prob[0]))\n",
    "        elif (y_new == \"Pull\"): \n",
    "\n",
    "            print(\"Pullover\")\n",
    "            print(\"{:.2f}%\".format(prob[1]))\n",
    "        else:\n",
    "            print(\"Unknown Class: ({})\".format(y_new))\n",
    "\n",
    "        \n",
    "        #Ausgabe \n",
    "        cv2.imshow('Prediction | press q to exit', img)\n",
    "        #User Input für das beenden des Darstellen  \n",
    "        if cv2.waitKey(0) & 0xFF == ord('q'):    \n",
    "            break\n",
    "\n",
    "\n",
    "# Stream schließen und Window Handling\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
